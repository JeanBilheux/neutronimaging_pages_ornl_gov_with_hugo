[
{
	"uri": "/prepare_venue/sample/",
	"title": "Sample Shipping",
	"tags": [],
	"description": "",
	"content": " Sample Shipping and/or Handling at HFIR Your samples must be confirmed in IPTS before shipping.\nGo to https://neutrons.ornl.gov/users/shipping-guide to get all the details about when, where, how \u0026hellip;. you can ship your samples.\n"
},
{
	"uri": "/prepare_venue/proposal_confirmation/",
	"title": "Proposal Confirmation",
	"tags": [],
	"description": "",
	"content": " To be completed by the Principal Investigator (PI) of the experiment at least 3 weeks before beam time.\n You can access your proposal using the IPTS page\n Confirmed samples (adding any new samples, and including composition)?\n Confirmed need for lab space?\n Confirmed experiment team that will be present at beam time (add any new members)?\n Confirmed experiment equipment and/or sample environment?\n"
},
{
	"uri": "/prepare_venue/safety/",
	"title": "Engineering &amp; Equipment Safety",
	"tags": [],
	"description": "",
	"content": " To be completed by the Principal Investigator (PI) of the experiment\n  Provided all safety documentation for user provided equipment immediately?\n Shipped/delivered all user provided equipment at least 2 weeks prior to beam time for electrical and safety inspection?\n Answered all safety related questions through IPTS?\n Ensured that sample environment requested equipment is available and compatible with experiment/beam line?\n Written a Job Hazard Analysis (JHA) for hands on work at HFIR?\n"
},
{
	"uri": "/prepare_venue/access/",
	"title": "Access",
	"tags": [],
	"description": "",
	"content": " This must be completed by all participants to the experiment before the first day of experiment.\n  Received training e-mail from user office (neutronusers@ornl.gov)?\n Completed online training if assigned? ORNL guess portal\n Scheduled onsite training and tour for HFIR access?\n Followed attached procedure to access CG-1D data?\n Followed attached procedure to access CG-1D analysis computer?\n"
},
{
	"uri": "/prepare_venue/",
	"title": "Before your Arrival",
	"tags": [],
	"description": "",
	"content": " Prepare your experiment In order to optimize your experiment time, we recommend you to go through the check lists from this Before your Arrival menu.\nFeel free to print out the pdf version and check out the items one by one.\n"
},
{
	"uri": "/tutorial/how_to_access_data/",
	"title": "Access your data",
	"tags": [],
	"description": "",
	"content": "  This will require that you complete 2 steps:\n Step 1: request access to our computer Step 2: reach your data   Step 1. Request access to our computers 1. Create an XCAMS account\nIf you have not done so, please create an XCAMS account 2. Request access to HFIR data\nYou can request access to your data by visiting this page https://user.ornl.gov/Account/Register?reqid=   Link not working?    \nTOP \n Step 2. Reach your data If the goal is to bring your data to your computer for local visualization and analysis -not recommended due to the size of the data and the tools we offer via our analysis computer - you can either use:\n FileZilla Cyberduck  \nUsing FileZilla 1. Install FileZilla.\n2 Create and configure a new bookmark\nEnter the information as followed:\n Host: analysis.sns.gov Port: 22 Protocol: Select SFTP - SSH File Transfer Protocol Logon Type: Normal User: \u0026lt;your xcams\u0026gt; Password: \u0026lt;your password\u0026gt;  Click Connect\nYou can now browse to your data by following the structure /HFIR/CG1D/IPTS-XXXX\n3. Import Data\nIf you want to copy your data to your local computer, simply DRAG and DROP the folder of interest into your Desktop display on the left side of the window.\n\nUsing Cyberduck 1. Install Cyberduck.\n2. Create and configure a new bookmark\nEnter the information as followed:\n SFTP (SSH File Transfer Protocol) Server: analysis.sns.gov Port: 22 Username: \u0026lt;your xcams\u0026gt; Password: \u0026lt;your password\u0026gt; SSH Private Key: None  Click Connect\nYou can now browse to your data by following the structure /HFIR/CG1D/IPTS-XXXX\n3. Import Data\nIf you want to copy your data to your local computer, simply DRAG and DROP the folder of interest into your Desktop.\nFile Structure If you get lost in the file system, here is a typical map of the file structure.\n\n"
},
{
	"uri": "/capabilities/",
	"title": "Capabilities",
	"tags": [],
	"description": "",
	"content": " Imaging Facilities   CG-1D radiography/tomography with cold neutron spectrum.    VENUS time-of-flight radiography/tomography with epithermal to cold neutrons spectra.   Xray CT complementary microCT capabilities   Technical Infos     Resolution: 1 micron ultimate resolution with 1mm field-of-view  Resolution: 65 microns with 50mm field-of-view  160 kV max  50mm or less sample size      "
},
{
	"uri": "/tutorial/how_to_access_computer/",
	"title": "Connect to our computer",
	"tags": [],
	"description": "",
	"content": " For any personal tutorial, demonstration or request, please contact Jean Bilheux.\nIn order to analyze or visualize your data, please follow the following recipe.\nConnect to our analysis computer Using your favorite browser, go to https://analysis.sns.gov\nEnter your XCAMS and your password and hit Login\nThe first time you log in, you will be presented the following display\njust click OK to finish up logging in.\nAnd if it is not the first time, you will probably see a black screen. Just click anywhere within the window to activate the screensaver log in.\nEnter your password and click Unlock.\nYou are now connected to our analysis computer.\n"
},
{
	"uri": "/faq/",
	"title": "Frequently Asked Questions",
	"tags": [],
	"description": "",
	"content": " Before Your Venue Proposal   How do I submit a proposal?    To learn more about submitting a proposal for beam time, go to neutrons.ornl.gov/users. To submit your proposal, go to the proposal system.    During your Experiment   Where can I stay?   A few options are available off-site and on-site. Check the neutron.ornl.gov users page for more infos.\n  Data Analysis    I forgot my XCAMS password   Simply go to How to reset password web page.\n    How can I browse my data?   Using ONCat, you will be able to  view your data view the metadata and get infos about such or such data set find an experiment using keyword More features coming soon      How can I get help analyzing my data?   Just contact Jean Bilheux to discuss your needs.\nBy going over your experiment together, Jean will show you how to run the current tools and will develop customed python notebooks if needed.\n    What are those \u0026#39;jupyter notebooks\u0026#39;?   The jupyter notebook developed by jupyter are an easy way to run python code using only a browser. By accessing our analysis computer, you won\u0026rsquo;t have anythign to install. Refer to our How To page to learn how to do that.\n    Where are my data and how can I access them?   The following tutorial will show you where are you data and how you can access them. Just go to How To \u0026gt; Access your data\n    I get a firefox error message when trying to start the jupyter notebooks on the analysis machine.   After double clicking the [start jupyter] icon, I get an Firefox error message telling me that I have another Firefox window opened.\nTo fix this issue, just open a terminal and type \u0026gt;rm -rf ~/.mozilla\nThis should fix your issue and you should be able to start the jupyter notebooks now.\n    Where do I find ImageJ (or Fiji) on the analysis computer?   Just follow the following path to find and start ImageJ. If you need to learn how to use ImageJ, check their tutorial web site\n    How to cite our work?    Use of CG1D beam line iMars3D iBeatles      Metadata of the images and their meaning   You can retrieve the metadata of your TIFF images using:  ONCat the jupyter notebook list_tiff_metadata.ipynb. Check How To \u0026gt; Start the python notebooks \n Tag NameDescription ImageWidthThe number of columns in the image ImageHeightThe number of rows in the image BitsPerSampleThe number of bits per component (ie. 16-bits or 32-bits for each greyscale pixel in our case) SampleFormatSpecifies how to interpret each data sample in a pixel (1 = unsigned integer) SamplesPerPixelThe number of components per pixel (1 in our case, which is grey scale) Compression1 = None PhotometricInterpretation1 = Min is black MakeStrThe detector manufacture (eg. 'Andor' or 'SBIG') ModelStrThe detector model number SoftwareStrEPICS areaDetector  \nTags 65000 to 650009 have no name and are used for timestamps and a unique ID\n Tag NameDescription 65000EPICS timestamp. The timestamp is made when the image is read out from the camera. Format is seconds.nanoseconds since Jan 1st 00:00 1990. 65001Unique ID for the image. Always 1 for single image acquisition, and incrementing up for camera and CT scans. Should always match the ImageCounter value. 65002EPICS timestamp (seconds part only) 65003EPICS timestamp (nanoseconds part only)  Scan Information  Tag NameDescription FileNameStrThe original file name part of the constructed file name (see below) InstrumentStr'CG1D' or 'VENUS' IPTSIPTS Number ITEMSITEMS Number SampleDescStrSample description (user entered) NotesStrUser notes DataSetStr'2D' or '3D' DataAcqModeStr'White Beam', 'TOF-cold/thermal', 'Epithermal' or 'Monochromatic' DataTypeStr'OB', 'Raw' or 'DF'  Camera/Image Information  Tag NameDescription ExposureTimeExposure time for the image (in seconds) ExposurePeriodExposure period for the image (Exposure Time + Readout Time in seconds). Not relevant for single image exposures. NumImages1= single image exposure (our normal mode of operation) ImageCounterAlways 1 for single image acquisition, and incrementing up for camera and CT scans. MinXMin X pixel (0 for full frame images) MinYMin Y pixel (0 for full frame images) SizeXSize of image in X dimension (should be equal to the ImageWidth value) SizeYSize of image in Y dimension (should be equal to the ImageLength value) TemperatureThe setpoint temperature (in C) TemperatureActualThe actual temperature read from the detector (in C)  Motor Position \u0026amp; Scan Device  Tag NameDescription MotScanDeviceStr'Small Rot' or 'Large Rot' used for this CT scan (if we are doing a camera scan or single image acquisition, this is not relevant) RotationActualActual position of the rotation stage used in the CT scan (or the previous scan if we are doing a camera scan or single image acquisition) MotRotTable.RBVLarge rotation table actual position MotRotTableLarge rotation table setpoint MotSmallRotTable.RBVSmall rotation table actual position MotSmallRotTableSmall rotation table setpoint MotLiftTable.RBVLift Table actual position MotLiftTableLift table setpoint MotShortAxis.RBVShort axis actual posiiton ...  TIFF File Header Example  TIFF Directory at offset 0x800008 (8388616) Image Width: 2048 Image Length: 2048 Bits/Sample: 16 Sample Format: unsigned integer Compression Scheme: None Photometric Interpretation: min-is-black Samples/Pixel: 1 Rows/Strip: 2048 Planar Configuration: single image plane Make: Unknown Model: Unknown Software: EPICS areaDetector Tag 65000: 837380408.136687 Tag 65001: 1 Tag 65002: 837380408 Tag 65003: 148080423 Tag 65010: FileNameStr:TiffHeaderTests Tag 65011: InstrumentStr:CG1D Tag 65012: IPTS:17255 Tag 65013: ITEMS:-1 Tag 65014: SampleDescStr:polarization test Tag 65015: NotesStr:polarization test Tag 65016: DataSetStr:2D Tag 65017: DataAcqModeStr:White Beam Tag 65018: DataTypeStr:Raw Tag 65019: ModelStr:DW936_BV Tag 65020: ManufacturerStr:Andor Tag 65021: ExposureTime:1.000000 Tag 65022: ExposurePeriod:5.451660 Tag 65023: NumExposures:1 Tag 65024: NumImages:1 Tag 65025: ImageCounter:1 Tag 65026: MinX:0 Tag 65027: MinY:0 Tag 65028: SizeX:2048 Tag 65029: SizeY:2048 Tag 65030: Temperature:-60.000000 Tag 65031: TemperatureActual:-57.830002 Tag 65032: MotScanDeviceStr:Small Rot Tag 65033: RotationActual:183.000132 Tag 65034: MotLiftTable.RBV:247.500452 Tag 65035: MotLiftTable:247.500452 Tag 65036: MotShortAxis.RBV:76.000000 Tag 65037: MotShortAxis:76.000000 Tag 65038: MotLongAxis.RBV:193.016000 Tag 65039: MotLongAxis:193.016000 Tag 65040: MotRotTable.RBV:182.996500 Tag 65041: MotRotTable:183.000000 Tag 65042: MotSmallRotTable.RBV:183.000132 Tag 65043: MotSmallRotTable:183.000000 Tag 65044: MotDetTable.RBV:200.000000 Tag 65045: MotDetTable:200.000000 Tag 65046: MotCameraVert.RBV:-51.699796 Tag 65047: MotCameraVert:-51.699796 Tag 65048: MotHoriTrans.RBV:28.000000 Tag 65049: MotHoriTrans:28.000000 Tag 65050: MotVertTrans.RBV:60.000000 Tag 65051: MotVertTrans:60.000000 Tag 65052: MotDiffuser.RBV:86.300000 Tag 65053: MotDiffuser:86.300000 Tag 65054: MotAperture.RBV:138.700000 Tag 65055: MotAperture:138.700000 Tag 65056: MotSlitVB.RBV:39.969938 Tag 65057: MotSlitVB:39.969938 Tag 65058: MotSlitVT.RBV:39.860484 Tag 65059: MotSlitVT:39.860484 Tag 65060: MotSlitHR.RBV:40.000000 Tag 65061: MotSlitHR:40.000000 Tag 65062: MotSlitHL.RBV:39.977781 Tag 65063: MotSlitHL:39.977781 Tag 65064: AndorCCDCooler:1 Tag 65065: AndorCCDTempStatusStr:Not stabilized at set point Tag 65066: AndorCCDPreAmpGain:0 Tag 65067: AndorCCDADCSpeed:2   \nWork With Us    Visiting Researcher Program   Link here\n    Minority Serving Institutions Partnership Program   Link here\n \n"
},
{
	"uri": "/tutorial/how_to_start_notebooks/",
	"title": "Start the python notebooks",
	"tags": [],
	"description": "",
	"content": "We provide a set of jupyter python notebooks. Those provide many advantages:\n rapid implementation for your special needs ease of use easy to modify if you need to use of python language (widely used in the scientific world) nothing to install for you as we take care of this for you when you use your analysis computer  To launch the jupyter notebooks, navigate to Applications \u0026gt; Analysis \u0026gt; Jupyter. Be patient as the python server starts a firefox browser with the right python environment and move to the right folder, for you!\nGetting the browser up and running with the notebooks page display takes around 10 to 20 seconds.\n To start a notebook, just click any of the .ipynb file (normalization.ipynb in this tutorial).\nFirst thing we recommend at this point is to make a copy of this notebook. This way, update of the notebooks will not overwrite your work.  Make sure you do not close the terminal window that you can find behind the browser as killing it will terminate your notebook sesssion.  "
},
{
	"uri": "/links/",
	"title": "Links",
	"tags": [],
	"description": "",
	"content": " Laboratory Utilities    ORNL User Program Guide   User Program Guide.     Submit a proposal   Go to the Proposal System.\n    Neutron Imaging Facility Official Web Page   Neutron Imaging Facility Official Web Page.     Neutrons (SNS/HFIR) Web Page   https://neutrons.ornl.gov/     ORNL Web Page   https://www.ornl.gov/     ORNL guess portal   https://user.ornl.gov  \nAnalysis Tools    Sample Activation Calculators   https://sac.ornl.gov/     Calculate Transmission and Scattering Power   https://webapps.frm2.tum.de/intranet/neutroncalc/     Neutron Transmission Calculator   http://apps.jcns.fz-juelich.de/toolbox/nXsection.php     Neutron Scattering Lengths and Cross Sections   https://www.ncnr.nist.gov/resources/n-lengths/     Neutron Activation and Scattering Calculator   ncnr.nist.gov/resources/activation/     Cold Neutron (HFIR) Transmission and Resonance   https://isc.sns.gov/  \nReferences    Standard Guide for Thermal Neutron Radiography of Materials   ASTM Guide for Thermal Neutron Radiography.     International Society for Neutron Radiology (ISNR)   International Society for Neutron Radiology  \nShortcuts  ONCat - https://oncat.ornl.gov/#/   "
},
{
	"uri": "/tutorial/how_to_run_notebooks/",
	"title": "Run a jupyter notebook",
	"tags": [],
	"description": "",
	"content": "  Our jupyter python notebooks are very straighforward to use but there are just a few key points you need to know.\n notebook layout run the notebook modify the notebook  \n Notebook layout \n Run the notebook Execute cells The notebooks must be run from top to bottom. Place the cursor in the first cell and either click the  icon, or by using the keyboard shortcut SHIFT + ENTER.\nThis is showing a busy notebook with the background cell green and the full circle at the top right corner of the notebook.\n\nFolder Navigation At least one time per notebook, you will need to select a folder or one or more files. This widget will look like this The UI is pretty self explanatory but you just need to know that:\n In the file/folder listing widget\n . means refresh of the current location .. means moving up one directory, or folder.  The file or folder will be really selected only once you have clicked the Select button at the bottom right corner.\n To select more than one file (when this option is available), CLICK first file then SHIFT + CLICK the last one. Or ALT + CLICK to individually select each file.\n  Output and widgets The cell is then executed and depending on the contain of this one, you may see or not an output to the cell. The output is always displayed just below the cell ran. In some of our notebooks you will see widgets that you will need to interact with. Here are a few examples of widgets you may encounter in your notebook.\nIn some notebooks, the output may even show up in the back of the notebook (the default cell output will give you a message that let you know where to look). Those outside widgets are more complex user interface such as the one shown here.\n\n Modify the notebook "
},
{
	"uri": "/tutorial/how_to_run_imars3d/",
	"title": "Do a CT reconstruction",
	"tags": [],
	"description": "",
	"content": "This tutorial explains how to use SNS jupyter notebook site to perform CT reconstruction.\nYou will find this tutorial here\n"
},
{
	"uri": "/tutorial/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": "You will find here various step by step tutorial showing you:\n how to access your data how to use our analysis computer how to run the analysis software etc.  "
},
{
	"uri": "/tutorial/how_to_do_bragg_edge_modeling/",
	"title": "Bragg Edge Modeling",
	"tags": [],
	"description": "",
	"content": " The following tutorial will guide, step by step, in a full Bragg Edge Modeling\nRequirements Input file You will need a VDrive file (vdrive_filename.txt) generated by the VULCAN instrument. This file should looks like this\nPython code You need to clone the bragg edge repository (this won\u0026rsquo;t be necessary as soon as the library has been deployed).\n start a terminal session clone braggedgemodeling repo\n cd ~/\ngit clone https://github.com/ornlneutronimaging/braggedgemodeling\ncd braggedgemodeling\n switch to texture branch\n git checkout texture\n add to python path\n export PYTHONPATH=$PWD:$PYTHONPATH\n  Step 1 - Prepare VDrive file In order to run the VDrive file through the Matlab code (step 2), we need to change the format of this file. To do so simply run the following command line (make sure you provide your own file path)\nNB: Add braggedgemodeling repo to python path !\n\u0026gt; python braggedgemodeling/scripts/vdrive_handler_to_mtex.py -i \u0026lt;full path to the vdrive filename.txt\u0026gt; -io \u0026lt;specify full filename of an intermediate file\u0026gt; -o \u0026lt;full path to output file, prefered extension .rpf\u0026gt;  Example\n\u0026gt; python scripts/vdrive_handler_to_mtex.py -i ~/Desktop/vdrive_filename.txt -o ~/Desktop/VULCAN.rpf -io ~/Desktop/intermediate_file  Here is what the output file should look like\nStep 2 - Matlab code  Right now, this code only works on VULCAN2 computer, so connect to https://vulcan2.sns.gov\n From there, launch Matlab2014a as this version is the only working for the code we are going to use.\n   Within Matlab, move to folder /usr/local/mtex-3.5.0 start startup_mtex from the Matlab command   We need to import the pole figure (file created in Step 1),  click the Import pole figure data blue line click + to select input file (~/Desktop/VULCAN.rpf) click Next \u0026gt;\u0026gt; and select Crystal Coordinate System Laue Group _ click several times Next \u0026gt;\u0026gt; or just Finish    A matlab script is created, make sure the specimen symetry is the one you specified in the GUI (BUG in the Matlab program!!!). If incorect, make sure you edit the file and replace it with the orientation you choosed.   Save the file and Run it. This will produce a few variables listed in the workspace window (right side of Matlab UI).   We need to create now the ODF file by just entering the following script in Matlab command line   And now the final step where we need to export the ODF data. But we first need to specify the number of graind orientation (default 5000) by editing the export_vPSC1 file.  FIX ME!!! find a way to make this script available to user (put it inside the mtex code\n Run the export_vPSC1 script from Matlab command line  And here is the final file created, texture.txt\n"
},
{
	"uri": "/tutorial/how_to_run_mcp_detector_correction/",
	"title": "MCP Det. Corr.",
	"tags": [],
	"description": "",
	"content": " The following tutorial will guide, step by step, in running the MCP correction program\nDescription Every single data acquired using the MCP detector needs to be corrected for detector efficiency.\nOld Way\nIn the past, one had to go through the following steps:\n start the windows command line tool locate the .exe script (using file browser) and drag and drop it into the command line window add a space in the command line locate the first image of the data set to correct Run the script and wait \u0026hellip; rename the folder correction created by the script grab this folder and move it to final location repeat for all other set of data  New Way\n start MCPcorrection program select root folder containing all data set select output folder click correction button  The parent folder must be the folder seating on top of the data folder! This looks confusing? Well just follow the following diagram. In such a case, you should select the first folder!  Step by Step Select the parent folder Make sure the folder you select contains all the data folders. Any other folder selected (higher or lower in the hierarchy will crash the application)!\nSelect the data folder to correct In the table, simply select all the data folder you want to correct. If a row is highlighted, this folder will be corrected\nSelect the output folder The data corrected will be moved into this folder\nNaming convention\nEach data set corrected will be copied inside a folder based on the name of all the images and inside a folder of the data folder + \u0026ldquo;_corrected\u0026rdquo;.\nFull correction animation Configuration This is where you can define the starting default folder, default output folder and also the run correction time out. The script run in the back requires user input to finish it, because we wanted to allow you to run several job one after the other without your input, we, using the time out value, stop the process manually. During testing, we found that 35s is long enough to allow all the files to be translater. In case you find that the time out shows up too early, you may need to increase the time here.\n"
},
{
	"uri": "/tutorial/how_to_use_oncat/",
	"title": "Use ONCat",
	"tags": [],
	"description": "",
	"content": " ONCat is a web tool that allows you to browse through the archived data.\nTo access ONCat, go to https://oncat.ornl.gov/#/\nHow to reach your data  Click EXPLORE enter your UCAMS and password Select your facility Select your instrument Select your IPTS, or perform a search to quickly find the right IPTS  Preview of your data By clicking the Thumbnails button, you can get a preview of every single file archived.\nHow to access the metadata From the top page of your IPTS, click the Files button at the top.\nA predefined list of metadata is display in the table.\nBut if you want to preview the entire list of metadata in your files, click your file name in the left column of this table and navigate through the tree shown.\n"
},
{
	"uri": "/tutorial/how_to_start_amira/",
	"title": "How to work with Amira",
	"tags": [],
	"description": "",
	"content": " This tutorial will show you how to start and then do some of the most basics things with Amira\nConnect to the analysis computer You need first to connect to the analysis computer. To do so, just follow the step by step tutorial in the how to connect to the analysis computer \nStart Amira Start a terminal session (click small black icon at the top of the screen) and type\namira  You should then see the Amira icon showing up\nNB: You may see some error messages in the terminal window, just ignore them !\nIf you see the following message, contact your local contact  Video Tutorials To get quickly started with Amira, here are a few YouTube videos that you may find interesting.\n Getting Started Tutorial Amira Basics Visualizing in 3D images Advanced Image Processing and Quantitative Analysis Measuring Diameter and Sphericity of Pores Getting Started with the Segmentation Editor Amira Image Segmentation Tutorial    CLICK HERE: Getting Started Tutorial     CLICK HERE: Amira Basics     CLICK HERE: Visualizing 3D Images     CLICK HERE: Advanced Image Processing and Quantitative Analysis     CLICK HERE: Measuring Diameter and Sphericity of Pores     CLICK HERE: Getting Started with the Segmentation Editor     CLICK HERE: Amira Image Segmentation Tutorial  CLICK HERE: Introduction to Python Scripting  CLICK HERE: Tutorial videos of add-ons   "
},
{
	"uri": "/tutorial/how_to_use_notebooks_locally/",
	"title": "How to use the notebooks locally on your computer",
	"tags": [],
	"description": "",
	"content": "  When working with your data files we recommend\nusing the notebooks from the analysis machine but we also want to provide the flexibility of using the notebooks from your own computer, especially if you want to modify or implement new notebooks.\nWe describe here the procedure to follow to bring those notebooks from our repository to your computer and how to set up your python environment to get all the right libraries.\nInstructions We provide here two ways to install the notebooks on your computer. The easy way using Anaconda Navigator, and the hard way using command line and terminal, in case you don\u0026rsquo;t want to use anaconda.\n Easy way - Anaconda Navigator Geeky/hard/fancy way - Command line  \n Easy way - Anaconda Step 1 - Download and install Anaconda Navigator Download and install the Anaconda Navigator by selecting the right version according to your operating system (OS) and following the instructions found in their web page.\nStep2 - Download the notebooks Go to the GitHub page (https://github.com/neutronimaging/python_notebooks) and click the green switch called Code and select Download ZIP\nOnce the download is done, navigate to the folder where the zip file has been created and simply double click to unzip the file. From there feel free to move that folder to its final location on your hard drive. For example, in my case, I moved it to /Users/j35/git/.\nStep 3 - Create conda environment  Start the Anaconda Navigator application.    From there, navigate to Environments  This is where you will import the environment.yml file from the python notebook folder you just downloaded and unzipped.\n Click Import No need to enter any text in the name field. This field will be populated automatically once you have selected the file (see next line). Click the folder icon and navigate to the python notebooks folder and select the file environment.yml.\n  The following animation shows you those steps\nStep 4 - Select the environment The new environment created, named neutron-imaging, should be selected by default. If not, activate it by clicking it.\nStep5 - Run the notebooks All you have to do then is launch the jupyter notebook engine. Go to the Home page and click the LAUNCH button in the jupyter notebook box.\nA browser window will show up with a list of all your files and folders. Navigate to the jupyter notebook folder you downloaded and unzip from github and go in the notebooks folder. From there, feel free to start any of the notebook!\n\n Geeky/hard/fancy way - Command line  for Mac/Linux for Windows  \n for Mac Step 1 - Download or clone the notebooks Select either one of the two ways to bring the notebooks to your computer\nDownload\nWe recommend using the latest tag (stable) version of the notebooks. Click either the zip or the tar.gz link.\nGo to your download folder and double click the file you just downloaded. Move this folder to your location of choice on your computer (for example, I used ~/git/ on my computer)\nClone\nOpen a terminal, move to the location where you want to clone (import) the notebooks and then type the clone command\n$ cd ~/git $ git clone https://github.com/neutronimaging/python_notebooks.git  Go to your download folder and double click the file you just downloaded. Move this folder to your location of choice on your computer (for example, I used ~/git/ on my computer)\nStep 2 - Install Anaconda on your computer Anaconda is a free program that will make the installation and management of the python libraries very easy. You can install either Anaconda (the full package) or just the light version called miniconda3\nStep 3 - Create a virtual python environment A virtual python environment is like a python version running on your machine but being isolated from the rest of the system. This way anything you will do in this environment, like installing new libraries, will not affect the rest of your computer.\nIn the following example we chose neutron_imaging as the name of our virtual environment. Feel free to replace it with whatever name makes more sense to you.\nTo do so, simply type the following command on your terminal\n$ conda create -n neutron_imaging python=3  Now let\u0026rsquo;s switch to that environment\n$ conda activate neutron_imaging  Step 4 - Set up environment Final step, we need to install all the libraries used by the notebooks. To do so, in your terminal, navigate to the notebooks folder your downloaded (tag version)\ncd ~/git/python_notebooks-0.1.0  and execute the installation script config_conda_env.sh\n$ bash config_conda_env.sh  This will take a while!\nStep 5 - launch the notebooks Last step, start the notebooks\n$ jupyter notebook  Your favorite browser will show up with the notebooks. Enjoy!\n\n for Windows Step 1 - Install Anaconda First thing to do will be do download and install anaconda. To do so, go to the anaconda download page.\nClick the Download button.\nClick the 64-Bit or 32-Bit version according to your machine.\nIf you don\u0026rsquo;t know, there is a higher chance that you are on a 64-Bit machine so give it a try. If you did not use wisely, the installation will fail and you will need to try the other version.\n Once the download of the program finished, go to your download folder and run the installer by double clicking it.\nKeep the default settings all the way by clicking next.\nStep 1 - Create conda environment Once the installation is done you will have a set of new tools in the Anaconda menu. Launch the tool called Anaconda Powershell Prompt\nThis is where we are going to import the imaging notebooks and installed the python libraries you will need to run the notebooks.\nOnce the terminal comes to life, we are going to create a folder that will contain the code to import. Let\u0026rsquo;s say we will call it git in your home folder\n$ cd ~/ $ mkdir ~/git $ cd git  Now we are going to create a special python environment that will allow us to stay away from the native python of the system, this is a recommended way to work with python packages.\n$ conda create -y -n neutron_imaging python=3.7  The name of our environment is called neutron_imaging and we are telling the system to install python version 3.7\nJust let the terminal install the libraries.\nOnce the installation is done, we need to activate that environment.\n$ conda activate neutron_imaging  Step 3 - Import or Clone Notebooks Select either one of the two ways to bring the notebooks to your computer\nDownload\nWe recommend using the latest tag (stable) version of the notebooks. Click either the zip or the tar.gz link.\nGo to your download folder and double click the file you just downloaded. Move this folder to your location of choice on your computer (for example, I used ~/git/ on my computer)\nClone\nOpen a terminal, move to the location where you want to clone (import) the notebooks and then type the clone command\n$ cd ~/git $ git clone https://github.com/neutronimaging/python_notebooks.git  Go to your download folder and double click the file you just downloaded. Move this folder to your location of choice on your computer (for example, I used ~/git/ on my computer)\nStep 4 - Import all libraries Now in the anaconda power shell terminal, import all the librairies by typing\n$ conda update -y -n base -c defaults conda $ conda install -y requests requests-oauthlib numpy scipy pandas scikit-image matplotlib plotly $ conda install -y nodejs qtpy pyqtgraph astropy $ conda install -y -c conda-forge ipywe lmfit $ pip install neutronbraggedge NeuNorm sectorizedradialprofile inflect ImagingReso ipywidgets $ pip install https://oncat.ornl.gov/packages/pyoncat-1.4.1-py3-none-any.whl  $ jupyter labextension install @jupyter-widgets/jupyterlab-manager $ jupyter nbextension enable --py widgetsnbextension $ jupyter lab build  You can now launch the Anaconda Navigator and select the environment you created and called neutron_imaging.\nNow you can go back to the HOME menu within the Anaconda Navigator and launch the Jupyter notebooks.\nFrom there, navigate to the folder ~/git/python_notebooks/notebooks/ to get access to all the notebooks!\n"
},
{
	"uri": "/tutorial/how_to_other/",
	"title": "Divers ...",
	"tags": [],
	"description": "",
	"content": "   How can I create a movie from a sequence of images?   A full tutorial showing you step by step how to create a movie using ImageJ is available at this post.\n  "
},
{
	"uri": "/tutorial/notebooks/",
	"title": "Notebooks Tutorials",
	"tags": [],
	"description": "",
	"content": "  A - B - C - D - E - F - G - H - I - J - K - L - M - N - O - P - Q - R - S - T - U - V - W - X - Y - Z\nB bin_images   bragg_edge_signal_vs_powder_peaks  bragg_edge_normalization   bragg_edge_profile  \nC calibrated_transmission  circular_profile_of_a_ring   combine_folders   combine_all_images_selected   combine_images_n_by_n  combine_images_without_outliers   create_list_of_file_name_vs_time_stamp  cylindrical_geometry_correction \nD deal_images   display_and_export_images_with_metadata_profile  display_and_export_images_with_timestamp  display_counts_of_region_vs_stack   display_file_names_vs_time_stamp   display_integrated_stack_of_images   dual_energy  \nE extract_evenly_spaced_files   extract_nexus_daslogs  \nF file_name_and_metadata_vs_time_stamp  fix_images   frederick_ipts  from_attenuation_to_concentration  from_dsc_time_info_to_ascii_file_vs_time \nG gamma_filtering_tool   group_images_by_cycle_for_panoramic_stitching  \nH hfir_reactor_element_analysis  \nI images_and_metadata_extrapolation_matcher   integrated_roi_counts_vs_file_name_and_time_stamp \nL list_element_bragg_edges  list_metadata_and_time_with_oncat   list_tiff_metadata \nM mcp_chips_corrector   metadata_ascii_parser   metadata_overlapping_images  \nN normalization   normalization_with_simplify_selection  \nO overlay_images  \nP panoramic_stitching   panoramic_stitching_for_tof   profile \nR radial_profile   registration  rename_files  resonance_imaging_experiment_vs_theory  rotate_and_crop_images  \nS sequential_combine_images_using_metadata \nT template_ui   topaz_config_generator \nW water_intake_profile_calculator  wave_front_dynamics \nTools File Selector  Select IPTS  \nExtra extract_sans_reductionlog_metadata  \n  Recently updated\n   Levels of documentation\n"
},
{
	"uri": "/tutorial/notebooks/bin_images/",
	"title": "Bin Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: bin_images.ipynb\nDescription This notebook rebin a image, or set of images. That means the pixels will be group according to the rebin parameter you will select.\nFor example, if you select a rebin value of 2, pixels will be group 2x2 (see images as an illustration of such a rebin) and those pixels will be averaged.\nIn the following example, we start with an image of 8 by 8 pixels. Please note the value of each pixels (number of counts).\nfig 1: original 8 by 8 image.\nThen we selected a rebin value of 2.\nfig 2: Rebin by 2 for a final image size of 4 by 4.\nIn the case where the width and/or height of the image can not be evenly divided by the rebin coefficient, the last uncompleted bin will be removed from the final image.  Select your IPTS Need help using the IPTS selector?\n Select the images to rebin Using the file selection tool, select the images you want to rebin.\nNB: After selection of the images, those will be automatically loaded in memory.\nSelect Bin Parameter It\u0026rsquo;s time to select your bin parameter. The cell will also gives you, for information, the size of your image before and after rebin.\nSelect Output Folder Just one more step. Select where you want those new images to be created. Once selected using the [folder selection tool]((/tutorial/notebooks/file_selector/#activate-search), the images will be automatically rebin and exported. The program will create a folder called after the input folder from where the initial images were retrieved inside the output folder you selected following this convention\n Input folder: my_data Output folder: my_data_rebin_by_2 (or whatever the rebin coefficient you selected)  "
},
{
	"uri": "/tutorial/notebooks/bragg_edge/",
	"title": "Bragg Edge",
	"tags": [],
	"description": "",
	"content": " Notebook name: bragg_edge.ipynb\nDescription Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Normalized Images Select the working folder. All the\n"
},
{
	"uri": "/tutorial/notebooks/bragg_edge_signal_vs_powder_peaks/",
	"title": "Bragg Edge - Signal vs Powder Peaks",
	"tags": [],
	"description": "",
	"content": " Notebook name: bragg_edge_signal_vs_powder_peaks.ipynb\nDescription The main goal of this notebook is to display the ideal Bragg Edges of a list of elements and compare their signature to the signal of a set of FITS (MCP data) taken. Experimental set up can be changed by:\n distance source - detector detector time offset  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect Working Folder Select the working folder using the file selector. If the time spectra file is part of the folder, it will be automatically loaded, if not, you will have the option to select the time spectra file next.\nCheck the file selection tool tutorial to learn how to use the file selector tool.  Selection of Sample in the Image In order to calculate the signal of the loaded images, you must define the location of your sample in the image. But before doing so, the program will need to load a random subset of those images. You will need to define how many images you want to use to select that sample. A subset has been defined for you by default. Using this value (N), the program will load N images randomly choosen within the list of images in the working folder.\nRemember The more images you want to load, the longer it will take.\nOnce this subset has been defined, running the next cell will bring a user interface that will allow you to define the location(s) of your sample.\nSelect Powder Elements It\u0026rsquo;s now time to select the powder elements for which you want to see the Bragg Edges on top of your signal.\nDefine Experiment Setup This is where you can set up your experiment and play with these values to make sure the Bragg Edges of the reference powder elements show up at the right lambda in your signal data.\nDisplay Bragg Edges vs Signal Feel free to play with the iPlot widgets (above the plot) to zoom, pan, \u0026hellip; etc\n"
},
{
	"uri": "/tutorial/notebooks/bragg_edge_normalization/",
	"title": "Bragg Edge Normalization",
	"tags": [],
	"description": "",
	"content": " Notebook name: bragg_edge_normalization.ipynb\nDescription This notebook is dedicated to the normalization of data set taken at the SNS.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect Sample Folder Select the sample folder using the file selector. If the time spectra file is part of the folder, it will be automatically loaded, if not, you will have the option to select the time spectra file next, or just ignore it and click the button dot not select any time spectra\nCheck the file selection tool tutorial to learn how to use the file selector tool.  If you select a time spectra file, it will be automatically copied into the output folder. this will facilitate the next step that is usually the extraction of the Bragg edges versus lambda/TOF into an ASCII file.\n The sample data will be automatically loaded.\nSelect OB Folder Just like you did for the sample data, select the folder containing the open beam (OB) data. Once you selected this folder the data will be automatically loaded.\nSelection of background region in the image You have the option to define a region of your image that is background for sure. This will improve the normalization.\nTo do so, you first need to specify how many random images you want to use to help the selection. The more images you select, the higher resolution your image will have but the longer it will take to display it. Usually the default number of images provided is a good compromise. If you can not see your sample in the image, just close the UI and increase the number of images to use.\nOnce the ROI selection tool UI show up, you can select, or not, 1 or more regions. You need to make sure that/those region(s) is/are away from the sample. If the sample covers the entire image, do not select any region! Once you are done, click OK to close the UI.\nRemember The more images you want to load, the longer it will take.\nPerform normalization Just run this cell to run the normalization algorithm.\nExport normalized data Select where you want to export all the normalized images. You have the option to create a folder if needed. The notebook will create a folder inside the output folder location you selected. The folder will be named after the input sample folder name. If input folder is test_data, the normalized folder will be test_data_normalized\nIf you selected, or if the program automatically found, a time spectra file, this file will be copied into the output folder.\n"
},
{
	"uri": "/tutorial/notebooks/bragg_edge_profile/",
	"title": "Bragg Edge Profile",
	"tags": [],
	"description": "",
	"content": " Notebook name: bragg_edge_profile.ipynb\nDescription This notebook has been implemented to produce an ASCII file of the average counts of the entire image, or of selected regions, versus lambda (Angstroms) and TOF (microS).\nThe ASCII output file will look like this\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nStep by step tutorial Select your IPTS Check the full tutorial here\nSelect Data Folder Select the data folder (usually normalized data via the bragg_edge_normalization notebook) using the file selector. If the time spectra file is part of the folder, it will be automatically loaded, if not, you will have the option to select the time spectra file next.\nCheck the file selection tool tutorial to learn how to use the file selector tool.  The sample data will be automatically loaded.\nCalculate Bragg edge profile Define Experiment Setup This is where you can set up your experiment and play with these values to make sure the Bragg Edges of the reference powder elements show up at the right lambda in your signal data.\nCalculate signal of sample region Select how many random files to use to select sample position Define how many images, selected randomly, you want to use to figure out the position of the sample. Remember that the more images you use, the longer it will take to display the ROI selection tool. The default value is usually a good compromise but feel free to increase this number if you are unable to see your sample due to low statistics.\nSelect the sample position In order to calculate the Bragg edge signal of your sample, you must select the region of your sample in your images. The same UI you used to select the background region will show up. Use the ROI tool to define one or more region overlapping your sample.\nCalculate This cell will calculate the Bragg edges data using the region selected.\nDisplay Bragg Edges vs Signal This cell is optional and you need to run it only if you want to display the Counts vs lambda.\nFeel free to play with the iPlot widgets (above the plot) to zoom, pan, \u0026hellip; etc\nExport ASCII data Select the output folder\nand then an ASCII file will be automatically created using the sample input folder as based name.\n"
},
{
	"uri": "/tutorial/notebooks/calibrated_transmission/",
	"title": "Calibrated Transmission",
	"tags": [],
	"description": "",
	"content": " Notebook name: calibrated_transmission.ipynb\nDescription The goal of this notebook is to display the average counts of region selected for each file. It\u0026rsquo;s possible to calibrate up to 2 regions by giving them a value. If a region with a mean counts of 100 is calibrated to 1 for example, all the other value displayed will use this new scaled defined. That means, if for a file the mean counts of a region is 200, the program will display 2. When 2 calibrated region are defined, a linear interpolation is used to dislay the mean counts of the region selected. When no calibrated region have been defined, the true (raw) mean counts are displayed.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Calibrated Transmission UI Presentation How Does it Work ? Define the Calibration Regions  Activate or deactivate the calibration region you want/do not want. Define the position and size of the region (using mouse in the image viewer, or by manual input) Select the value corresponding to this region Select the file to use corresponding to that region  Define the Measurement Regions  Go the Measurement Regions tab Add new regions by clicking the + button at the bottom right Change the position (using mouse in image viewer or by manual input in the table) Remove regions using the - button  Summary Tab The Summary tab display the list of files, time stamp, relative time (using the first file as reference or time 0), and mean counts calibrated for each measurement regions.\nExport Calibrated Transmission You can now export the calibrated transmission signal for each file by clicking the Export Calibrated Transmission button. Just select the output location. The file name created will be based on the input data folder and will look like this.\nIf input data file is light_loop1_flow2, the output file will be named light_loop1_flow2_calibrated_transmission.txt\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tutorial/notebooks/circular_profile_of_a_ring/",
	"title": "Circular Profile of a Ring",
	"tags": [],
	"description": "",
	"content": " Notebook name: circular_profile_of_a_ring.ipynb\nDescription This notebook will create an ASCII output file of the average counts of the pixel within a given ring versus angle position. Top vertical being the angle 0 and going clockwise.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images Select a folder that contains all the images to get profile from. The radiographs will be loaded in memory and a progress bar will display the progress of the loading.\nCheck this tutorial if you need help using the file selection tool\n launch the user interface The user interface contains 3 main parts: * on the left - preview of the radiographs loaded + grid + ring selection * on the right - ring, grid and angle bin settings * hiding in the slider on the far right - result of circular profile of the ring\nring selection Using the mouse + left click, you can move the ring around and use the grid tool (size and color can be modified) in order to place with high precision the center of the ring. Feel free to use the mouse wheel to zoom in and/or out the image.\nThen you can modify the ring size using either the mouse directly on the plot, or the widgets on the right of the preview. Via the plot, click and little square box on the bottom right of the ring to change the size of the ring. You can also play with the inner radius slider on the right to change the size.\nTo change the thickness of the ring, play with the thickness slider on the right of the preview.\nAngle cursor It\u0026rsquo;s possible to measure the angular position of any element relative to the custom center defined by playing with the angle cursor widgets.\nprofile generator tool The notebook will create a table of counts versus angles. The angles bins (degrees) slider allows you to get a thinner or coarser profile. To visualize the angle value of each pixel of the ring, click the \u0026ldquo;angles matrix of ring\u0026rdquo; radio button on top of the preview image.\ncalculate profiles Click the calculate profiles button to produce the profile of the ring. A progress bar displayed at the bottom of the ui will show the progress of the calculation as the program extracts the profile for every single radiograph your loaded.\nhow is the profile calculated?\nThe following diagram will help explain the math behind the profile calculation.\nIn order to calculate the angular position of every single of the image relative to the top vertical position, the center of the pixel is used. Each center gets an angular value. Then when the angular axis has been defined by playing with the angular bin, every pixel is associated with the closest angle value. If one more than 1 pixel falls in the same angle bin, the average of all the pixel counts in this bin is used.\nIn the previous figure,\n pixel a and b are part of the same angular bin and the average of pixel A and B will be used for that angle all angles are calculated by using the center of the pixels as shown in figure d pixel c has its center outside of the ring and then, won\u0026rsquo;t be used  Once the process is done, the right part of the UI will expand and display the list of images loaded. Select any, one or more, of those images to display the profile of mean counts versus angle value.\nFeel free to play with the plot style widgets, as well as zoom and pan of the plot.\nBrowsing the profiles It\u0026rsquo;s possible to quickly locate the elements position calculated by the algorithm by clicking the profile plot. The angular position of that point will be displayed on the left display.\nExport profiles Once you are done, click export profiles \u0026hellip; to export the profiles data into an ASCII file.\n"
},
{
	"uri": "/tutorial/notebooks/combine_all_images_selected/",
	"title": "Combine All Images Selected",
	"tags": [],
	"description": "",
	"content": " Notebook name: combine_all_images_selected.ipynb\nDescription This notebook allows you to combine the images selected. 3 algorithms are currently available\n Arithmetic Mean   Geometric Mean   Add  Not seeing the algorithm you want to use? Please let me know and I will add it (Jean Bilheux)\n Example:\nInput\n image001.fits image002.fits image003.fits  Output\n image001_image002_image003.fits  Select your IPTS Need help using the IPTS selector?\n Select the images to merge Using the file selection tool, select the images you want to combine.\nMerging method It\u0026rsquo;s time to select your merging algorithm (check the description at the top of this web page for the explanation of the algorithms).\nSelect output location Using the folder selection tool, select the location where you want to create the combine image.\nPersonalize the output file name If you don\u0026rsquo;t like the default output file name offered, you have here the option to define your own.\nMerging Running the next cell will create the merge image and will inform you of the progress via a progress bar.\n"
},
{
	"uri": "/tutorial/notebooks/combine_folders/",
	"title": "Combine Folders",
	"tags": [],
	"description": "",
	"content": " Notebook name: combine_folders.ipynb\nDescription There are situations where you want to combine similar images from different folders. This is the notebook you were looking for.\nYou will need to select the input folders first. The program will let you know if they do not have the same number of images and will stop there.\nThen you will just need to specify the kind of combination you are looking for (add, mean) and then the output folder\nFig 1: Example of input folders\nFig 2: What the output may look like\nSelect your IPTS Need help using the IPTS selector?\n Select the Input Folders Using the folder selection tool, select the folders you want to combine.\nThe program will then automatically check that the input folders have the same number of files.\nIf they do, you will see the following green message\nBut if they don\u0026rsquo;t, you will quickly see that something is wrong when you see the red message\nThe only requirement of this notebook is that the folders must contain the same number of images.\nHow many folders do you want to combine together? According to the number of folders selected, the program will let you choose the way you want them combined.\nFor example, if you select 4 folders, you will have the option to combine them by 2, 3 or 4. If you select 3, the 4th folder won\u0026rsquo;t be used.\nHow do you want to combine the folders What algorithm do you want to use to combine them. You have the option to add or to mean those images.\nNot seeing the algorithm you want to use? Please let me know and I will add it (Jean Bilheux)\n Select output folder Using the folder selection tool, select the output location.\nA double progress bar (folder and file progress) will show you the progress of the combination of the folders.\nIn our example, let\u0026rsquo;s pretend we selected to combine the folders 2 by 2, the output will look like this\n"
},
{
	"uri": "/tutorial/notebooks/combine_images_n_by_n/",
	"title": "Combine Images n by n",
	"tags": [],
	"description": "",
	"content": " Notebook name: combine_images_n_by_n.ipynb\nDescription This notebook allows you to combine the images contain in the folder you selected by group of n by n using 3 different algorithms.\n Arithmetic Mean   Geometric Mean   Add  Not seeing the algorithm you want to use? Please let me know and I will add it (Jean Bilheux)\n Example:\nlet\u0026rsquo;s pretend you selected a folder containing the following 21 images\nInput\n image001.fits\n image002.fits image003.fits image004.fits image005.fits image006.fits image007.fits image008.fits image009.fits image010.fits\n image011.fits image012.fits image013.fits image014.fits image015.fits image016.fits image017.fits image018.fits image019.fits image020.fits image021.fits  and you decided to combine the first 4 images, then the following 4, and so on\nThis will produce 5 files\n 4_files_combined_0001.tif 4_files_combined_0002.tif 4_files_combined_0003.tif 4_files_combined_0004.tif 4_files_combined_0005.tif  where the first one will be the combination of image001.fits, image002.fits, image003.fits and image004.fits\nNB: Because there were 21 images to start with, the last image was dropped (image021.fits) as 21 can not be evenly divided by 4!\nHow does the notebook work? Select your IPTS Need help using the IPTS selector?\n Select the folder containing the images to merge/combine Using the file selection tool, select the folder\nMerging method It\u0026rsquo;s time to select your merging algorithm (check the description at the top of this web page for the explanation of the algorithms).\nHow do you want to combine those images This is where you specify how you want to combine them. If you select 2, the first 2 images will be combined, then the next 2, and so on. If the number of images can not be evenly divided by this coefficient, then the last images won\u0026rsquo;t be used.\nSelect output location Using the folder selection tool, select the location where you want to create the combine images.\nMerging Once you have entered the output folder, the images will be automatically merged and a progress bar will let you know of the progress of the operation. Then finally, the notebook will let you know when it\u0026rsquo;s done and show you where those files have been created.\nWorking with TOF data If you are working with TOF data set, where a _Spectra.txt file is present, the notebook will automatically create a new _Spectra.txt file according to the merging parameters you selected.\n The first column of the file, time, will be the average of the corresponding row/files combined The second column, total counts will use the same algorithm than the one you selected in the notebook.  If a Spectra file has been located and a new one created, the full file path of that file will be displayed in the notebook\n"
},
{
	"uri": "/tutorial/notebooks/sequential_combine_images_using_metadata/",
	"title": "Combine Images Sequentially using the Metadata Information",
	"tags": [],
	"description": "",
	"content": " Notebook name: sequential_combine_images_using_metadata.ipynb\nDescription This notebook was implemented to automatically combine runs according to any of the metadata you select.\nIn other words, let\u0026rsquo;s pretend you take 10 images at a given sample position, move the sample then take another 10 images, until the end of the cycle. The algorithm will look at the metadata value you selected, in this case 2 motor positions, and if they match within a given range (1 by default), the images are considered to be of the same sample at the same place. They will be combined. If one of the metadata is outside the error range, or if the name of the run changed, then this is considered to be a different run or/and different location.\nThe notebook will create a dictionary of run # -\u0026gt; position# -\u0026gt; list of files. This then wll be used to combine the images using 1 of 3 different algorithms (check the following notebook to learn more about those algorithms [combine_images]())\nTutorial Select your IPTS Need help using the IPTS selector?\n Select the Input Folders Using the folder selection tool, select the folders containing the images you want to work on.\nselect metadata to match Using the first file of the folder selected, the notebook will display the list of metadata (and their value) to let you select which metadata we need to check to decide if the new file needs to be combine to the previous one or not.\nBy default, 2 metadata are selected\n MotLiftTable.RBV MtLongAxis.RBV  How do you want to combine the folders What algorithm do you want to use to combine them. You have the option to add or to mean (arithmetic mean or geometric mean) those images.\nNot seeing the algorithm you want to use? Please let me know and I will add it (Jean Bilheux)\n Create and Checking Merging List The program will load the data, in order to retrieve the metadata, and will create the list that will be used in the final step to merge the data. If anything seems wrong during this step, contact me (Jean Bilheux)\nSelect output folder Using the folder selection tool, select the output location.\nA double progress bar (folder and file progress) will show you the progress of the combination of the folders.\n"
},
{
	"uri": "/tutorial/notebooks/combine_images_without_outliers/",
	"title": "Combine Images without Outliers",
	"tags": [],
	"description": "",
	"content": " Notebook name: combine_images_without_outliers.ipynb\nDescription The goal of this notebooks is to combine images (mean) after removing, for each pixel, the pixel with the min and max counts.\nThe main purpose is to improve the statistics of the images by removing pixel with very low or very high counts such as the \u0026ldquo;gamma\u0026rdquo; pixels. This is the reason why a minimum of 3 images minimum needs to be provided for each position to combine.\nBut in order to let the program figure out how to combine the images together from the full stack you selected, the notebook will list all the images found in the folder you selected and will let you choose the first images to combine together. The program will then determine the part of the name that does not change between those images and then automatically use it on all the other images of the folder to find out how to combine the entire set.\nDue to a limitation of unix, make sure the last digit of the file name has enough digit to cover the entire stack. This is because unix treats image called image2 as being after image12. For this purpose, use the renamed notebook\nso for example, let\u0026rsquo;s pretend the first few images are And if you select the first 4 images The images will then be combined by looking at the part of the string that does not change 20200821_Femur_0010_000_000\nTutorial Select your IPTS Need help using the IPTS selector?\n Select how you want to combine the first images Using the folder selection tool, select the folder containing the data to combine.\nThe program will then display all the files found in the folder and will ask you to select how you want to combine the first images. As explained in the introduction, the algorithm will then determine the fix part of the names between those files to learn how to combine the rest of the stack of images. Select at least 3 images!\nThe notebook will then display how the new output files will be named and their corresponding initial images combined.\nSelect output folder Using the folder selection tool, select the output location.\nThe notebook will create a folder named based on the input folder name and will show you the progress of the conversion via a progress bar.\n"
},
{
	"uri": "/credits/",
	"title": "Contacts",
	"tags": [],
	"description": "",
	"content": "            Hassina Bilheux - Instrument ScientistExpertise: HFIR and SNS imaging beam lines   Short Bio ...   Dr. Hassina Bilheux obtained her Ph.D. in Physics at the Univ. of Versailles, France. Her work focused on plasma physics at the Oak Ridge National Laboratory’s Physics Division.\nShe has developed neutron imaging capabilities at ORNL’s High Flux Isotope Reactor CG-1D beamline and is prototyping neutron imaging at the Spallation Neutron Source. Her interests comprise the development of advanced neutron imaging techniques at the Spallation Neutron Source for material and biological applications.   bilheuxhn@ornl.gov (865) 384 - 9630 (865) 574 - 0241 researchGate Scholar Google    Yuxuan Zhang (Shawn) - Instrument ScientistExpertise: Resonance Imaging zhangy6@ornl.gov     Jean Bilheux - Computer Instrument ScientistExpertise: Python Notebooks and Data Analysis bilheuxjm@ornl.gov (865) 406 - 1704 jbilheux.com jeanbilheux.pages.ornl.gov    Erik Stringfellow - Scientific Associate stringfellde@ornl.gov (865) 576-6432    Brianne Beers - Graduate Student    -- Past Team Members  Paris Cornwell, ORNL Keita DeCarlo, Princeton Univ. Indu Dhiman Granger Endsley, Oak Ridge High School Vincenzo Finochiarro, Italy Sarah Hammer, Virginia State Univ. Susan Herringer, Brown Univ. Misun Kang, Univ. of TN-Knoxville Felix Kim, Univ. of TN-Knoxville Chad Lani, Penn State University Jiao Lin, ORNL Lou Santodonato, Advanced Research Systems, Inc Gian Song, Univ. of TN-Knoxville Sophie Voisin, Univ. of TN-Knoxville Lakeisha Walker, ORNL  "
},
{
	"uri": "/tutorial/notebooks/create_list_of_file_name_vs_time_stamp/",
	"title": "Create List of Files of Names vs Time Stamp",
	"tags": [],
	"description": "",
	"content": " Notebook name: create_list_of_file_name_vs_time_stamp.ipynb\nDescription This notebook extracts the acquisition time of the selected files and output an ascii file with the following informations\n full path of File name time stamp (unix format) time stamp (user format) time offset (ms) relative to first image  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect Data Set Select Images you want to check\nCheck the file selection tool tutorial to learn how to use the file selector tool.  Once you have selected your data, you will see a progress bar as the time stamp metadata are retrieved from the files.\nSelect Output Folder Simple, just navigate to the location where you want your ascii file written.\nOutput Folder Created The Ascii file created will look like this\n#filename, timestamp(s), timestamp_user_format, timeoffset(s) /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0001.tiff, 1532610101.2023919, 2018-07-26 09:01:41, 0.0 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0002.tiff, 1532610101.2320013, 2018-07-26 09:01:41, 0.02960944175720215 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0003.tiff, 1532610101.261922, 2018-07-26 09:01:41, 0.059530019760131836 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0004.tiff, 1532610101.2918322, 2018-07-26 09:01:41, 0.08944034576416016 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0005.tiff, 1532610101.32187, 2018-07-26 09:01:41, 0.11947822570800781 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0006.tiff, 1532610101.352108, 2018-07-26 09:01:41, 0.14971613883972168 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0007.tiff, 1532610101.3818908, 2018-07-26 09:01:41, 0.17949891090393066 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0008.tiff, 1532610101.411917, 2018-07-26 09:01:41, 0.20952510833740234 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0009.tiff, 1532610101.4418778, 2018-07-26 09:01:41, 0.2394859790802002 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0010.tiff, 1532610101.4718854, 2018-07-26 09:01:41, 0.26949357986450195 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0011.tiff, 1532610101.5023768, 2018-07-26 09:01:41, 0.2999849319458008 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0012.tiff, 1532610101.531988, 2018-07-26 09:01:41, 0.32959604263305664 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0013.tiff, 1532610101.5619035, 2018-07-26 09:01:41, 0.3595116138458252 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0014.tiff, 1532610101.59197, 2018-07-26 09:01:41, 0.38957810401916504 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0015.tiff, 1532610101.6220326, 2018-07-26 09:01:41, 0.41964077949523926 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0016.tiff, 1532610101.6519294, 2018-07-26 09:01:41, 0.4495375156402588 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0017.tiff, 1532610101.6820183, 2018-07-26 09:01:41, 0.4796264171600342 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0018.tiff, 1532610101.7119684, 2018-07-26 09:01:41, 0.5095765590667725 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0019.tiff, 1532610101.7419527, 2018-07-26 09:01:41, 0.5395607948303223 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0020.tiff, 1532610101.7720513, 2018-07-26 09:01:41, 0.5696594715118408 /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-21115/Huggies_3cm_thick/20180726_Huggies_3cm_0000_0021.tiff, 1532610101.802108, 2018-07-26 09:01:41, 0.5997161865234375 ...  "
},
{
	"uri": "/tutorial/notebooks/cylindrical_geometry_correction/",
	"title": "Cylindrical Geometry Correction",
	"tags": [],
	"description": "",
	"content": " Notebook name: cylindrical_geometry_correction.ipynb\nDescription Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images You need to provide the list of samples, OB and DF (if needed). To do so, just SHIFT + ENTER the following cell to display a selection tool wizard.\nThe dialogbox will start listing the files from the IPTS folder you selected in the first cell. Feel free to navigate to find your data set.\n"
},
{
	"uri": "/tutorial/notebooks/deal_images/",
	"title": "Deal Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: deal_images.ipynb\nDescription There will be cases where a folder contains several different experiment, or set up, or measure. You will need to sort those images into their own folder. Hopefully this notebook can save you a ton of time by doing it automatically. The algorithm to \u0026lsquo;group\u0026rsquo; the images is based on the name of those files.\nThe following picture illustrates the principle of the deal\nThis program assumes that the file names follow this schema\ntext\u0026lt;image_ref\u0026gt;_\u0026lt;image_index\u0026gt;.\u0026lt;ext\u0026gt;  If it does not, run the notebook rename_files.ipynb.\n Select your IPTS Need help using the IPTS selector?\n Select the Input Folder Using the folder selection tool, select the folder that contains the images you need to separate.\nSelect the Output Folder Using the folder selection tool, select the folder that will contain the folders of all the deal images.\n"
},
{
	"uri": "/tutorial/notebooks/display_and_export_images_with_timestamp/",
	"title": "Display and Export Images",
	"tags": [],
	"description": "",
	"content": "Notebook name: display_and_export_images_with_timestamp.ipynb\n"
},
{
	"uri": "/tutorial/notebooks/display_counts_of_region_vs_stack/",
	"title": "Display Counts of ROI vs Stack",
	"tags": [],
	"description": "",
	"content": " Notebook name: display_counts_of_region_vs_stack.ipynb\nDescription In this notebook, you will be able to get the average number of counts of a given region vs all the images of the selected folder.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect the Images Select the folder containing the images you want to process using the File Selector. The images will then be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Launch the UI SHIFT + ENTER in the next cell (Launch UI) to start the interface.\nUI Presentation Region of Interest (ROI) By default, a ROI is already defined for you in the top left corner of the preview region.\nTo move it, click inside the ROI (edges will turn yellow). To resize it, grab the bottom right corner and move it to resize it.\nThe Average counts of this entire region, for all the images from the folder, will be displayed live at the bottom of the interface.\nTime Spectra (OPTIONAL) "
},
{
	"uri": "/tutorial/notebooks/display_file_names_vs_time_stamp/",
	"title": "Display File Names vs Time Stamp",
	"tags": [],
	"description": "",
	"content": " Notebook name: display_file_names_vs_time_stamp.ipynb\nDescription This notebook extracts the acquisition time and displays\n time stamp vs file index relative time stamp offset vs file index (offset between each file) absolute time stamp offset vs file index (offset relative to first file loaded)  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect Data Set Select Images you want to check\nCheck the file selection tool tutorial to learn how to use the file selector tool.  Once you have selected your data, you will see a progress bar as the time stamp metadata are retrieved from the files.\nDisplay Time Stamp The next cell will plot on the left side the relative time offset in seconds, and on the right side, the absolute time offset in seconds.\nRelative time offset (s)\nThis is the time between each image.\nrelative_time(i) = acquisition_time(image(i)) - acquisition_time(image(i-1))  Absolute time offset (s)\nThis is the time spent since we started to acquire the images. For the first image, this absolute time is 0 of course.\nabsolute_time(i) = acquisition_time(image(i)) - acquisition_time(image(0))  Here is the plot we got when using an acquisition time of 30ms List Files Loaded The next cell display a list of all the fulle, relative and absolute time stamps.\n"
},
{
	"uri": "/tutorial/notebooks/display_and_export_images_with_metadata_profile/",
	"title": "Display Images and Metadata",
	"tags": [],
	"description": "",
	"content": "Notebook name: display_and_export_images_with_metadata.ipynb\n"
},
{
	"uri": "/tutorial/notebooks/display_integrated_stack_of_images/",
	"title": "Display Integrated Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: display_integrated_stack_of_images.ipynb\nDescription This notebook will simply the integrated image of all the images (TIFF or FITS) from the input folder.\nSelect your IPTS Need help using the IPTS selector?\n Select the Input Folder Using the folder selection tool, select the folder that contains the images you need to separate.\nIntegrated image Then the integrated image is displayed with a colorbar.\n"
},
{
	"uri": "/tutorial/notebooks/dual_energy/",
	"title": "Dual Energy",
	"tags": [],
	"description": "",
	"content": " Notebook name: dual_energy.ipynb\nDescription This notebook provides an automated way to determine the best contrast within an energy range of a region of interest selected.\n((add link to paper describing the technique here))\nSelect your IPTS Need help using the IPTS selector?\n Select data input folder Select the input data folder. This folder should contain all the images recorded by the MCP detector. By default this folder will contain the time spectra file needed by the program. If it does not, a new window will ask you to browse for this file once the data have been loaded.\nUsing the folder selection tool, select the folder that contains the images you need to work on.\nlaunch the user interface (UI) A user interface will show up and may be hidden behind the current browser, make sure you check for it if you don\u0026rsquo;t see it coming to life.\nThis UI will allow you to select the region of the image you want to investigate. Then the size of the bin to use and then launch the calculation.\nSelect your region of interest Using your mouse, move and resize the region of interest displayed on top of the preview (left part of the UI). Any action on this box will update the right plot of the Mean transmission vs file index / TOF or lambda.\nSelect profile range and size of bins Using range selection in right plot, select the range you want to work on as well as the size of the bins to use. Those bins will be displayed inside the range you selected. All images within each bin will be group into one image of average counts and used in the next step.\nCalculation As soon as your click the Calculation tab, the algorithm will run. This algorithm will use the region of interest you selected in the left image and will average the counts of this region, then bin all the images within each bin and calculate the ratio of any combination of bins. The ratio with the difference to 1 will be highlighted in the table and the corresponding ratio of images displayed in the right side of the Calculation tab.\nBelow the master table, you will find a smaller table that summarizes the infos related to the \u0026lsquo;optimum\u0026rsquo; bin ratio such as the file index used in the bins, TOF range and lambda ranges.\nExport image You have the possibility to export the current image displayed in the table by clicking the Export image \u0026hellip; button below the image on the right. Simply select the location where you want to create that image and click OK. The image will be, by default, named using the input folder name as prefix and then the bins used to calculate it.\nfor example: IPTS-25778_normalized_bin18_divided_by_bin9.tif\n"
},
{
	"uri": "/tutorial/notebooks/extract_evenly_spaced_files/",
	"title": "Extract Evenly Spaced Files",
	"tags": [],
	"description": "",
	"content": " Notebook name: extract_evenly_spaced_files.ipynb\nDescription This notebook allows you to copy into a new folder (extract) 1 every n files from the source folder. You will need to provide the skipping factor n in the notebook. You will also have the option to rename those files, as they are copied, in order to keep a linear increasing index starting at index 0.\nExample:\nlet\u0026rsquo;s pretend you selected a folder (/Users/j35/my_data/) containing the following 21 images\nInput\n image_001.fits\n image_002.fits image_003.fits image_004.fits image_005.fits image_006.fits image_007.fits image_008.fits image_009.fits image_010.fits\n image_011.fits image_012.fits image_013.fits image_014.fits image_015.fits image_016.fits image_017.fits image_018.fits image_019.fits image_020.fits image_021.fits  and you decided to extract 1 every 5 files in the Desktop.\nThe notebook will create the folder called /Users/j35/Desktop/my_data_1_every_5_files and will copy the following files there\n image_001.fits\n image_006.fits image_011.fits image_016.fits image_021.fits  or if you decide to rename them\n image_0000.fits\n image_0001.fits image_0002.fits image_0003.fits image_0004.fits  How does the notebook work? Select your IPTS Need help using the IPTS selector?\n Select the folder containing the images to extract Using the file selection tool, select the folder\nExtraction coefficient Select the number of images you want to skip. The notebook will give you live the list of files that will then be extracted.\nRename or not Files This is where you have the option to rename of not the output files.\nSelect output location Using the folder selection tool, select the location where you want to create the combine images.\nExtracting Once the output folder has been selected, the files will be automatically extracted (copied) into the output folder. Then a message will let you know when the process is done and where you can find the files copied.\n"
},
{
	"uri": "/tutorial/notebooks/extract_sans_reductionlog_metadata/",
	"title": "Extract Metadata from SANS ReductionLog",
	"tags": [],
	"description": "",
	"content": " Notebook name: extract_sans_reductionlog_metadata.ipynb\nDescription This notebook creates an ASCII file of any of the metadata selected in the ReductionLog file. This file is created at the end of each reduction and contain a lot of information about the reduction process. Metadata from all ReductionLog files are listed side by side in a comma separated format as shown here.\nIn this format, all the metadata selected of a given input file are on the same row. You will then have as many rows as input files selected.\nStep by Step Demo Select your instrument Select your HFIR SANS instrument. This will allow the program to start directly from the instrument folder.\nSelect the ReductionLog files Using the folder selection tool, select all the ReductionLog files (*.hdf) you want to use.\nOnce you selected all those files, the notebook will automatically display all the metadata you can extract. This list of metadata has been provided by the instrument team. This allows to only display the metadata of interest and hide most of the one you don\u0026rsquo;t really care.\nSelect list of metadata to extract Use a combination of CLICK, SHIFT + CLICK and CTRL + CLICK to make sure you selected all the metadata.\nSelect output folder Using the folder selection tool, select the folder where you want to create the ascii file.\n"
},
{
	"uri": "/tutorial/notebooks/extract_nexus_daslogs/",
	"title": "Extract NeXus DASlogs",
	"tags": [],
	"description": "",
	"content": " Notebook name: extract_nexus_daslogs.ipynb\nDescription Some experiments required saving some metadata such as a furnace temperature over time in order to match each image file with the proper metadata. This notebook allows you to select 2 axis of metadata to retrieve. Usually time and value of that metadata.\nFor example, this tutorial will use the PV (name of DAS variable) called BL3_SE_ND1:CH2:PV which is in fact the temperature of a furnace. One will select the time array and then the data array. The notebook will then extract those information and will also format the time axis as follow:\n relative time, default time recorded in the NeXus, absolute time, using relative time + starting time of NeXus global relative time. This is in the case you selected more than 1 NeXus, the global relative time will use the time the first NeXus was started as reference, or time t=0s  The notebook will then create an output ASCII file named after the metatdata selected that will look like this\nHow does the notebook work? Select your IPTS Need help using the IPTS selector?\n Select the NeXus Using the file selection tool, select all the NeXus you want to retrieve metadata from.\nSelect the Metadata to extract Using the first NeXus selected the notebook displays the list of metadata found in the DASlogs entry. Make you way through the tree to select your x and y-axis.\nThe notebook offers the possibility to interpolate the data by defining the interpolation step to use. The algorithm will then use a linear interpolation using the scipy splrep method.\nSelect output location Using the folder selection tool, select the location where you want to create the ASCII file\nFull Demo "
},
{
	"uri": "/tutorial/notebooks/file_name_and_metadata_vs_time_stamp/",
	"title": "File Name and Metadata vs Timestamp",
	"tags": [],
	"description": "",
	"content": "Notebook name: file_name_and_metadata_vs_time.ipynb\n"
},
{
	"uri": "/tutorial/notebooks/file_selector/",
	"title": "File Selector",
	"tags": [],
	"description": "",
	"content": " Description The File Selector tool allows you to navigate through the file system to select files or folders.\nNavigation Manual Definition of Folder In order to make your way to your file(s)/folder(s), you can either chose to define your folder using the manual input field and click Jump\nOr/And you can navigate using the file browser box.\nSelection To select a folder, you have two ways:\n select the folder and click SELECT  enter the folder and click SELECT   To move up the tree (go to the parent folder), select ..\nMoving Up the Tree Filter for File Selection You can sometimes narrow down the list of files/folders displayed by using the filter option.\nAll Features Tutorial If you want to check all the features offered by the fileselector tool, go to the Fileselector hands-on tutorial\n"
},
{
	"uri": "/tutorial/notebooks/fix_images/",
	"title": "Fix Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: fix_images.ipynb\ndescription This notebook allows you to fix a set of images by replacing all the pixels having the same value, by another value. For example, you can replace all the Inf values by 0 or np.NaN.\nHere is the list of things you can fix:\n Inf values NaN values Negative values  and here is the list of things you can replace with:\n np.NaN 0  Select your IPTS Need help using the IPTS selector?\n Select your images Using the files selection tool, select the images you want to fix.\nGive statistics In order to get an idea of what you need to correct, the next cell will display the following informations.\n name of the file total number of pixels in the image number and percentage of pixels with negative values number and percentage of pixels with infinite (negative or positive) values number and percentage of pixels with non defined (NaN) values  A slider allows you to check those parameters for each of the images you loaded.\nDisplay images and histograms This is where you are able to visualize the corrections you are about to apply to the data. You can select which corrections you want to apply and see the effect on the image and its histogram.\nYou can make the following corrections\n Negative values -\u0026gt; np.NaN or 0 Infinite values -\u0026gt; np.NaN or 0 NaN values -\u0026gt; np.NaN or 0  where np.NaN is the numpy NaN.\nYou can slide through the images to display\n the raw image (top left corner) the raw histogram (top right corner) the new corrected image (bottom left corner) the new histogram (bottom right corner)\n  Export images Using the folder selection tool to select the output location of all the images corrected.\n"
},
{
	"uri": "/tutorial/notebooks/frederick_ipts/",
	"title": "Frederick IPTS",
	"tags": [],
	"description": "",
	"content": " Notebook name: frederick_ipts.ipynb\nDescription This notebook will re-group the data using the metadata recorded in the name of the files.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nSorting Files Using the name of the files, the program will retrieve the Temperature (T) and Pressure (P) of the data set.\nHere is what those file names look like\nThe program will then re-group the files by time stamp first and then by T and P parameters.\nThis process may take some times as the program is loading all the data and calculating the groups.\nDisplay Images By running the display images cell, a UI pops up that will allow you to browse your data using the groups extracted from the previous step.\n"
},
{
	"uri": "/tutorial/notebooks/from_dsc_time_info_to_ascii_file_vs_time/",
	"title": "From .dsc Time Info to ASCII File vs Time",
	"tags": [],
	"description": "",
	"content": " Notebook name: from_dsc_time_info_to_ascii_file_vs_time.ipynb\nDescription There are cases where you will need to use the metadata from the dsc file to retrieve the time information as the files themselves do not have this information any more (because they are not the original images anymore, because they have been moved, \u0026hellip;).\nSo this notebook will use the dsc files and match the time stamp information they contain with the base file name. Then will create an ascii file of the equivalent TIFF image vs time stamp\nINPUT\nfolder containing .dsc files\nOUTPUT\nfilename_vs_timestamp.txt\nsample_0000.tif 1045454545 sample_0001.tif 1045454546 sample_0002.tfi 1045454547  Instructions Select your IPTS Need help using the IPTS selector?\n Select the DSC Folder Using the folder selection tool, select the folder that contains the .dsc files.\nSelect the Image Folder Using the folder selection tool, select the folder that contains the images (TIFF or FITS) to match with the dsc files.\nSelect the Output Folder Using the folder selection tool, select the folder where the ascii file listing the image files and their time stamp will be created.\nAscii File Created Once you have selected the output folder, the ascii file will be automatically created and will look something like this\nwhere the columns information are in order\n base file name time stamp (unix format) time stamp (user format) acquisition time (s)  "
},
{
	"uri": "/tutorial/notebooks/from_attenuation_to_concentration/",
	"title": "From Attenuation to Concentration",
	"tags": [],
	"description": "",
	"content": " Notebook name: from_attenuation_to_concentration.ipynb\nDescription This notebook takes normalized data (attenuation) as input and will apply the formula defined to the data. The data are then exported as TIFF. This formula convert attenuation into concentration values.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect data folder Select the folder that contains the normalized images\nNeed help using the File Selector?\n Define conversion formula Define the conversion equation to use where\n A(x,Y) is the Attenuation (normalized) image H(x,y) is the concentration array that will be created  Converting data Run this cell to convert the data. A progress bar will show you the evolution of the correction, then disapear once it\u0026rsquo;s done.\nSelect output folder location Select the location where the output folder will be created based on the name of the input folder\nif input folder is data_03 output folder will be data_03_concentration\nNeed help using the File Selector?\n Video showing entire process "
},
{
	"uri": "/showcase/",
	"title": "Gallery",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tutorial/notebooks/gamma_filtering_tool/",
	"title": "Gamma Filtering Tool",
	"tags": [],
	"description": "",
	"content": " Notebook name: gamma_filtering_tool.ipynb\nDescription This notebook will allow you to compare data loaded without any correction against data loaded with gamma filtering on. You will be able to change the gamma filtering coefficient to optimize the cleaning of the gammas without dammaging the images.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect Images Simply select all the images you want to work on.\nCheck the file selection tool tutorial to learn how to use the file selector tool.  Display Images click the Auto scale to initialize the image just after launching the UI.  Mouse Infos / Zoom and Pan Moving the mouse over the raw or filtered image will give you its value in the status bar (bottom left) of the UI. Also any zoom or pan transformation in one of the image will be reproduced in the other image.\nChanging the filtering coefficient After changing the gamma filtering coefficient and hitting ENTER, the entire stack of data will be reloaded using the new filter coefficient. The table will show you the new percentage and number of pixels cleaned. The gamma filtered plot will be refreshed to display the new cleaned selected image.\nGamma Filtering Algorithm If you wonder how the gamma filtering algorithm works and what is the meaning behind this magic gamma filtering coefficient\nHere is the workflow:\n user determine the gamma filtering coefficient (coefficient). Value between 0 and 1. Image per image, the program calculate the average counts (image_average_counts). if the coefficient * pixel_value \u0026gt; image_average_counts then this pixel is considered to be a gamma and is replaced by the average value of its 8 neighbor pixels.  Feel free to move the plot around and resize them!  Histogram of Raw and Filtered Data Sets A newer version of the UI offers the histogram of the images before and after filtering. This helps figuring out where the gamma are located.\n"
},
{
	"uri": "/github/",
	"title": "Github Repositories",
	"tags": [],
	"description": "",
	"content": "Our gloal is to only develop open source tools. You will find here a list of the major repositories hosting our programs\n jupyter notebooks used in the analysis of the data python_notebooks python library used for normalization neunorm Imaging Resonance python library imagingReso iBeatles for Bragg Edge fitting iBeatles set of jupyter widgets ipywe Root analysis library RootPlantProcessing  "
},
{
	"uri": "/tutorial/notebooks/group_images_by_cycle_for_panoramic_stitching/",
	"title": "Group Images by Cycle for Panoramic Stitching",
	"tags": [],
	"description": "",
	"content": " Notebook name: group_images_by_cycle_for_panoramic_stitching.ipynb\nDescription There are cases where several images have to be taken to cover the entire sample, as this one is going through changes. To automate the acquisition, the system acquires the images going from one full cycle, full coverage of the sample, to the next one without any changes in the location of the files, or even information in the name of the files. This notebook will look at all the images of a given folder and will group them by cycle, then it will sort them in order to facilitate the work when stitching them together. This sorting can be something like working in rows first from left to right.\nThe following illustration shows this type of acquisition\nThe goal being to go from a continuous list of files to a sorted list of cycles\nTutorial Select your IPTS Need help using the IPTS selector?\n Select the input folder Using the folder selection tool, select the folder containing the data to work on.\nThe program will then automatically group the data by cycle using 2 PVs, data acquisition metadata, called MotLiftTable and MotLongAxis. Those PVs record the vertical and horizontal position of the sample table. A simple change can be done in the code to allow the program to use other, or more, PVs (contact Jean Bilheux to learn more about this advanced feature).\nThe notebook will list the name of the input folder and the number of files, only TIFF, found in that folder. Then on the left you will find the list of groups created. Just click on any of those groups to see the name of the files that belong to the group and the corresponding metadata.\nSort files Running the cell will allow you to select how your want to sort the files within each group/cycle.\nFor example, if you define MotLiftTable as your first variable, the program will sort the files by their MotLiftTable metadata, then will move to the second parameter to sort the files having an identical MotLiftTable.\nThe following sketches illustrates how this work when ascending is selected for both cases. Selecting descending will reverse the images for that given PV.\nThe bottom widgets allows you to browse through the groups and see how the files will be sorted and renamed.\nSelect the output folder Using the folder selection tool, select the output location.\nThe notebook will create a folder named based on the input folder name and then will create a folder for each group of images.\n"
},
{
	"uri": "/tutorial/notebooks/hfir_reactor_element_analysis/",
	"title": "HFIR reactor elements analysis tool",
	"tags": [],
	"description": "",
	"content": " Notebook name: hfir_reactor_element_analysis.ipynb\nDescription This notebook will use the output ASCII file created by the circular profile of a ring notebook and will display the peak of each element for each file, side by sided, to study any displacement of the elements.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the ASCII file Select the profile ASCII file created by the circular_profile_of_a_ring notebook.\nCheck this tutorial if you need help using the file selection tool\n launch the user interface The interface contains 2 tabs. The first tab Profiles, will allow you to select the threshold to use to isolate the peaks. The second tab Elements Position will display the position of each peak for each file loaded.\nProfiles tab First thing to do is to visualize the profile of the tif file loaded (left table) and remove the rows that do not need to be part of the calculation, for example like the second row selected in the following screenshot.\nA default threshold has been selected for the data set loaded. Make sure that threshold makes a clear center cut of every single data set to use.\nFor example, the following examples shows what kind of selection to avoid, and then a better one.\nOnce you are satisfy with the selection, click Calculate Elements Position. The program isolate all the local maximum, representing the center of each element (red symbols).\nMake sure you browse through a random list of input data profile files to make sure you don\u0026rsquo;t see any out of position peaks, as shown in the following case.\nIn this case, increase the minimum number of points in a peak number in order to force the program to treat only the real peaks of at least n data points.\nOnce the elements positions have been calculated, clicking the Display ideal positions of n elements will show in the top plot the ideal positions of those n elements by using the full 360 degrees span starting at the first element found.\nElements Position tab This tab displays the peak position of each element for each file. y-axis is the file index and x-axis is the angular position. Zoom in the top plot to really isolate each element and compare their angular position through the slices (projections).\n2 tabs are provided at the bottom to quickly locate possible issues.\n all peaks found missing peaks  The first tab called all peaks found displays in red the element position that are outside of the tolerance range (defined at the bottom of the window).\nThe second tab called missing peaks considers the perfect table of number of files per ideal number of elements and shows in red the elements that have not been located in that particular \u0026ldquo;ideal\u0026rdquo; location.\nOne should starts worried when the red pattern repeats over multiple images!\n Right click any of the cells of those 2 tables will display the angle value and the corresponding file name.\nExport You can then just export the data into an ASCII data file by clicking the Export table data \u0026hellip; button at the bottom right corner.\n"
},
{
	"uri": "/tutorial/notebooks/images_and_metadata_extrapolation_matcher/",
	"title": "Images and Metadata Extrapolation Matcher",
	"tags": [],
	"description": "",
	"content": " Notebook name: images_and_metadata_extrapolation_parser.ipynb\nDescription There are cases where you need to define the metadata value of a given image. This is challenging when the file recording the metadata has no correlation with the images taken. This notebook will allow you to calculate, according to the time stamp of the image file, the metadata value.\nThis notebook takes 2 text files as input:\n filename vs timestamp text file\n created by the notebook create_list_of_file_name_vs_time_stamp.ipynb  metadata vs timestamp text file\n created by metadata_ascii_parser   or\n created by list_metadata_and_time_with_oncat   Using those input files, the notebook will create a new text file of the file name and the corresponding metadata values you previously selected.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select the file name vs time stamp text file Using the file selection tool, select your metadata file.\nAs specified in the notebook, this is the file you created using the notebook create_list_of_file_name_vs_time_stamp.ipynb\nThis file looks like this\nSelect the metadata vs time stamp text file This file can be created\n using the notebook metadata_ascii_parser when the metadata have not been saved inside the image file (ex: hardware used to apply, and record, metadata was not connected to our data aquisition system (DAS))  or\n using the notebook list_metadata_and_time_with_oncat when the metadata are inside the image file.  Need help figuring out the metadata stored in your image file? Check this tutorial on how to use ONCat  Select data to merge You have now the option to select which of the metadata you want to keep and extrapolate for the given image files.\nUse CTRL + Click to select more than one metadata.\nExtrapolate and display results Running this cell will give you a preview of the interpolation of the data. Original values of the metadata are displayed in green and extrapolated values are displayed in orange. The orange data will be the one exported in the final text file as those corespond to the image file time stamps.\nSelect output folder Using the folder selection tool, select the output folder.\nOnce you have selected this folder, the output ascii file is automatically created and a message informs you of the name of the file as well as the location of this file.\n"
},
{
	"uri": "/tutorial/notebooks/integrated_roi_counts_vs_file_name_and_time_stamp/",
	"title": "Integrated ROI Counts vs File Name and Time Stamp",
	"tags": [],
	"description": "",
	"content": " Notebook name: integrated_roi_counts_vs_file_name_and_time_stamp.ipynb\nDescription This notebook will create an ASCII file with the following information\n file index file name time stamp of file Mean or total number of counts of each region of interest for each image  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images Simply select all the images you want to work on.\nCheck the file selection tool tutorial to learn how to use the file selector tool.  Presentation of the UI Step by Step ROI selection You have the option with this UI to select more than one region of interest (ROI). Click the + button on the right to add a ROI, and - if you want to remove the ROI selected. You can also enabled or disabled any of the ROIs.\nTo modify any of the ROI, you can either:\n move or resize the ROI directly from the Image window manually change x0, y0, width or/and height in the ROI table  The total conts vs file index plot will be updated live as you modified the ROI. This plot displays the mean or total counts of the ROIs for each image (1 image = 1 data point)\nIntegration Algorithm The current implementation provides 2 algorithms to integrate the counts within each ROI\n Add - sum counts of all the pixels in the ROI Mean - average counts of all the pixels in the ROI  The total counts vs file index plot will be updated live as you change the algorithm.\nExport the Counts vs file name and time stamp information Click the Export Counts vs File Name and Time Stamp \u0026hellip; button to create the ascii file version of the data found int the Summary Tab table.\nThe following 3 images shows an example where 3 ROIs have been created, how the summary tab looks like and the final output file created.\n"
},
{
	"uri": "/tutorial/notebooks/list_element_bragg_edges/",
	"title": "List Bragg Edges of an Element",
	"tags": [],
	"description": "",
	"content": " Notebook name: list_element_bragg_edges.ipynb\nDescription This notebook lists the given number of hkl, d-spacing and Bragg Edges values for one of the listed element.\nIf you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select the entries Select the element and the number of data you want to see.\nTable Result The next cell will display the following information\n name of the material you selected lattice value crystal structure if the program used the local metadata table or retrieved the information from the NIST web site directly d-spacing and Bragg edges values for each hkl  Export table You have the option to export the table information as a CSV (comma separated file format).\nSelect the output folder where the file will be created. The file will then be created automatically using the following file name convention\nbragg_edges_of_\u0026lt;name_of_element\u0026gt;.txt\n"
},
{
	"uri": "/tutorial/notebooks/list_metadata_and_time_with_oncat/",
	"title": "List Metadata and Time with ONCat",
	"tags": [],
	"description": "",
	"content": " Notebook name: list_metadata_and_time_with_oncat.ipynb\nDescription Using the ORNL Database service ONCat in the back, users can create an ASCII file with the acquisition time and metadata of interest selected. The output file will look like this\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect TIFF images Select the list of tiff images using the file selector\nNeed help using the File Selector?\n Log in to ONCat In order to be able to retrieve the metadata from our database (ONCat) you will need to log in by typing your XCAMS password, then hit ENTER. A message will show you if you entered the right password or not.\nSelect Metadata to Keep The notebook will list all the metadata found in the first image you selected with an example of values, again found in the first file. Select all the metadata you want to see in the final ASCII output file. Use CTRL + CLICK to select more than one metadata.\nCreate and Export ASCII File It\u0026rsquo;s now time to select your output folder.\nNeed help using the Folder Selector?\n The program will automatically name the file based on the input folder\nFor example:\n input folder: 20180814\n ASCII file: 20180814_metadata_report.txt\n  "
},
{
	"uri": "/tutorial/notebooks/list_tiff_metadata/",
	"title": "List TIFF Metadata",
	"tags": [],
	"description": "",
	"content": " Notebook name: list_tiff_metadata.ipynb\nDescription This notebook will list the value of the metadata you selected for the full stack of images you loaded. You will then have the option to export this table in an ascii (comma separeated) file.\n select your tiff images select the metadata you want to see metadata are listed (OPTION) select folder to export the table  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect TIFF images Select the list of tiff images using the file selector\nNeed help using the File Selector?\n Select metadata to display Using the first image selected, the program will determine the list of metadata available and will display the list here. Select the one you want to output.\nMetadat displayed The selected metadata value for all the images is displayed in a dropdown list.\nExport table Select output folder location and click export in next cell.\n"
},
{
	"uri": "/tutorial/notebooks/math_images/",
	"title": "Math with Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: math_images.ipynb\nDescription This notebook allows you to perform simple math (addition or subtraction for now) on a stack of images.\nThe current requirement is that you can add or subtract a single image (that you will select) on a stack of images.\nNot seeing the algorithm you want to use? Please let me know and I will add it (Jean Bilheux)\n Select your IPTS Need help using the IPTS selector?\n Select the images to operate on Using the file selection tool, select the images you want use in the math.\nselect the second image to use in the math Using the file selection tool, select the image you want to use on the other side of the math.\nMath Method You can currently only select add or subtraction.\nRecap The program gives you a recapitulation of the math you are about to perform, such as:\n the number of files affected the math algorithm the name of the second file image  Select output location Using the folder selection tool, select the location where you want to create the final images.\nOnce the files have been created, a message will let you know where you can check the result.\n"
},
{
	"uri": "/tutorial/notebooks/mcp_chips_corrector/",
	"title": "MCP Chips Corrector",
	"tags": [],
	"description": "",
	"content": " Notebook name: mcp_chips_corrector.ipynb\nDescription This notebook will allow you to correct individual MCP chips by applying an offset as shown here.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Folders to Process Using the folder selector tool, select the folder you want to work on. This folder must contain the entire FITS images to correct. All the FITS images, except the SummedImg, will be corrected.\nNeed help using the File Selector?\n Interface Presentation How Does it Work ? The first tab Setup allows to define the chips that needs to be corrected. The image displayed is the integrated signal of all the images selected. A profile region, that can be resized and reoriented, allows to calculate automatically the average counts on either side of a chip gap. The difference of average counts leads to the calculation of a corrector coefficient that is applied to the working chips (red framing around it). The second tab with correction displays the resulting correction applied to the integrated image.\nStep by Step Step 1 - Select the profile to use In this first step, you need to define a region, either vertically or horizontally, that overlap the working chip and another chip to estimate the correction to apply. If the profile selected is horizontally for example, the program will integrate all the pixels in the vertical direction within the profile region. The profile is then displayed on the right side of the UI with the average counts for either side of the gap, gap highlighted as a green vertical line.\nThe profile region can be resized using the 2 handles as shown here.\nStep 2 - Select working chip and position profile Using bottom widgets, select the chip you want to correct. The working chip will be highlighted by a red contour in the display window. Then move, and resize if needed, the profile to make sure it covers either the working chip and another chip to use as reference counts. Ideally, try to profile a common feature on either side of the chip gap.\nStep 3 - Visualize correction and repeat correction on all images Jump to the second tab called with correction to visualize the correction on the integrated image.\n If correction seems to work, click bottom switch to select output folder where all the images will be corrected. if correction still seems to be off, you can define a manual correction value in the bottom right widget.  "
},
{
	"uri": "/tutorial/notebooks/metadata_ascii_parser/",
	"title": "Metadata Ascii Parser",
	"tags": [],
	"description": "",
	"content": " Notebook name: metadata_ascii_parser.ipynb\nDescription Because of the large variety of sample environment used, we need to face a large variety of metadata files outputs. Those metadata files contain the sample environment data, such as temperature of a furnace, pressure of a cell, voltage of a power supply, etc. This notebook will allow you to select this metadata and isolate the set of information you want to retrieve. A new ascii file will then be created in a more common format that other notebooks will be able to use.\nIf your metadata file can not be parsed by this program, this means we need to write a new plugin for that particular file, please contact Jean Bilheux.\n The metadata file currently supported by this application looks like this:\nand will create the following type of output file\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select the metadata file Using the file selection tool, select your metadata file.\nSelect the infos you want to keep The program will list the name of each column of metadata, as well as a data/time columns created by the program itself. Select the metadata you want to keep (any number of columns is allowed).\nUse SHIFT or COMMAND + CLICK to select more than one metadata.\nSelect output folder and filename It is now time to export the new ascii metadata file.\nDefine the output file name. The extension .txt will be automatically added if you don\u0026rsquo;t specify it. Then select the output folder.\nThe new comma separated ascii file will have the following columns\nIndex, timestamp (s), metadata you selected \u0026hellip;\n"
},
{
	"uri": "/tutorial/notebooks/metadata_overlapping_images/",
	"title": "Metadata Overlapping Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: metadata_overlapping_images.ipynb\nDescription This notebook allows you to add a dimension scale to your images. You can also add a given metadata value for each of the images, or a graph showing the entire metadata plot and the current image metadata position on this graph.\n Scale added on top of image  Metadata of current image  Graph of all metadata and current metadata value   Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Profile UI Presentation How Does it Work ? Scale Select the scale option to add a dimension marker on top of the images. You can define:\n orientation of the scale size and label color thickness of the line position of the scale/label in the image  Metadata When using metadata, you can display the current metadata as a string. But if you chose to, you can also display a graph showing the current file metadata position over the entire set of images metadata.\nText If you are working with a TIFF image, you will have the option of selecting one of the metadata available. Feel free to change the label of this one if needed. You can also define your own metadata by editing the table, or loading a file_vs_metadata file created by a notebook specially dedicated to this purpose (WORK IN PROGRESS).\nIt\u0026rsquo;s sometimes necessary to format the default metadata value (especially if you want to display the graph). To do so, right click in the right column of the table to reach the metadata string parser (string filter). Then define the first and last part of the string to remove  Graph Advanced feature The Advanced Table \u0026hellip; button brings a new window that allows you to perform linear operation on various metadata at the same time and display the result of this operation.\nIn order to define a new complex formula:\n select a metadata to use via the top combo box click + button to add it to the math table change the coefficient in front of the new metadata if needed (default value is 1) keep adding new metadata the same way  If a metadata needs to be removed from the equation, select the column and click -\nClick OK to validate the equation and to return to main interface.\nThe following animation demo how the advanced feature works.\nExport NB: Your application will look a little bit different from this animation\nYou can now export all your images. The PNG files created will be a copy of the current UI image preview.\n"
},
{
	"uri": "/",
	"title": "Neutron Imaging",
	"tags": [],
	"description": "",
	"content": " User Home Page Welcome to the ORNL Neutron Imaging Website! This site is designed to help you with the preparation of your experiment and subsequent data processing and analysis. If you are not familiar with neutron imaging and may be interested in collaborating with us, visit the publications page to review the science we do.\nFor industrial applications, please contact Hassina Bilheux\nWe recommend that you discuss your experiment with the instrument team as soon as you receive approval of your beam time.\n Main features  Prepare your arrival: Everything you will need to do before coming to our laboratory. Capabilities: list of imaging instruments available. How to: short tutorials such as how to access your data, connect to the computers, etc. Frequently Asked Questions: answers to the most frequent questions we got from our users. Links: handy links.  We would like to thank the contribution from the research community in the implementation of this web site, and always welcome your comments to improve it (contact Jean Bilheux).\n   Web site logo: Ryzewski K., Herringer S., Bilheux H.Z., Walker L., Sheldon B., Voisin S., Bilheux J., Finocchiaro V., Neutron imaging of archaeological bronzes at the Oak Ridge National Laboratory Physics Procedia, 43, 343-351 (2013).\n "
},
{
	"uri": "/tutorial/notebooks/normalization/",
	"title": "Normalization",
	"tags": [],
	"description": "",
	"content": " Notebook name: normalization.ipynb\nDescription This notebook normalized the imaging data (tiff or fits) by removing the background and fixing the fluctuations of the neutron beam. You will need:\n select your images select your open beam (OB) optional - select the dark field (DF) optional - select one or more background region in your sample images run the normalization select output folder where the normalized images will be saved  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images You need to provide the list of samples, OB and DF (if needed). To do so, just SHIFT + ENTER the following cell to display a selection tool wizard.\nThe dialogbox will start listing the files from the IPTS folder you selected in the first cell. Feel free to navigate to find your data set.\nCheck the file selection tool tutorial to learn how to use the file selector tool.   Select your sample images click Next Step\u0026gt;\u0026gt; Select your OB images click Next Step\u0026gt;\u0026gt; OPTIONAL Select your DF images click Next Step\u0026gt;\u0026gt; to let the program load all your images.  Select Background Region SHIFT + ENTER to run the cell. A new User Interface (UI) will come to life. If you can not see the UI, check behind the notebook window.\nIn order to speed up the display of the data, the notebook randomly select 5% of the stack of sample image selected. If you want to change that coefficient, edit the config.py file found in the __code folder and change the variable value called percentage_of_images_to_use_for_roi_selection.  Just click OK if you do not want to select any region of interest (ROI).\nIf you want to provide one, or more, ROI, click + on the right of the GUI and move/resize the ROI using the mouse, or the table values.\nNormalization This cell runs the normalization and let you know the progress of the calculation via a progress bar.\nExport Select where you want to output the normalized data, then run the following cell. Once the output folder selected, a folder name after the input data folder is created and will contain all the normalized data.\n"
},
{
	"uri": "/tutorial/notebooks/normalization_with_simplify_selection/",
	"title": "Normalization with Simplify Selection",
	"tags": [],
	"description": "",
	"content": " Notebook name: normalization_with_simplify_selection.ipynb\nDescription This notebook normalized the imaging data (tiff or fits) by removing the background and fixing the fluctuations of the neutron beam. You will need to follow these steps:\n select your sample images folder Select the OB from the list proposed select output folder where the normalized images will be saved  The big improvement of this notebook compared to the old normalization notebook is that now, the notebook takes care of finding all the OB and DF for you, and matches them with your sample data by making sure that:\n the slits have the same position the acquisition time is identical the detector type is identical  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelecting the Sample Images Simply navigate to the folder containing all the data your want to normalize. The program will then list the files with the most dominant extension, for example, if you have a folder with 10 tiff images and 2 fits, only the 10 tiff images will be used. All the sample images will be grouped according to the following criteria:\n acquisition time slits positions detector type  The notebook will then retrieve all the OB and DF of the same IPTS by looking into the /raw/ob and /raw/df folders respectively of your IPTS folder. The OB and DF that match the sample criteria will then be associated to their sample data.\nAt that point, you have the power to finalize the selection:\n For each configuration, you can reject it from normalization by turning off the switch named Normalize this configuration   The list of OB proposed include ALL the OBs found with matching metadata (see above) in the corresponding IPTS, no matter how long before or after they were acquired. By default they are all selected in the list widget. Feel free to narrow down that selection by manually selecting them (see next animation).   You can also narrow down that selection by setting up yourself a time range before and after the sample data runs (see the next animation)  Normalization workflow This table will summarizes the data reduction that is about to take place. If a config has no OB, the table will let you know that this config won\u0026rsquo;t be normalized unless you provide at least one OB. Also, if you decided to turn off the normalization of any particular config, you will see it in that table.\nSelect Output Folder Select the output location where you want all the normalized folders to be created. Then a message will let you know when the normalization is done and the name of the files created.\nCheck the folder selection tool tutorial to learn how to use the folder selector tool.  "
},
{
	"uri": "/tutorial/notebooks/overlay_images/",
	"title": "Overlay Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: overlay_images.ipynb\nDescription This notebook will overlay (merged) two folders of images taken with different resolution. The low resolution, wide angle, images will be scaled in order to fit the high resolution. The high resolution can be placed inside the low resolution images automatically or manually.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nloading the Images High resolution images Select the folder that contains all the high resolution images you want to use.\nCheck this tutorial if you need help using the file selection tool\n Move on to the next cell to select the low resolution images.\nLow resolution images Repeat the process for the low resolution images. Make sure the two folders have the same number of images\nLaunching the interface The next cell will bring the main UI to life.\nUse the splitters to resize any of the windows.  The first tab will allows you:\n to roughly rescale the low resolution images to fit the pixel size of the high resolution images place the high resolution images at the right place inside the low resolution images  Step 1 Using the RED and BLUE markers. The goal being to place the RED markers at the corresponding spot in the high resolution image and the low resolution image. Repeat it for the BLUE markers.\nMake sure you use the mouse to facilitate the selection by Zooming (wheel) or panning (left and drag click).\nStep 2 The second step allows you to improve the alignment of the selected high resolution image and apply that changes (scaling factor, xoffset and yoffset) to all the other images.\nA couple of tools are available to help you position the images, the profiler and transparency tools.\nManual scaling, xoffset and yoffset It\u0026rsquo;s possible to manually define the scaling factor, the xoffset, and the yoffset position of the currently selected high and low resolution images. Just enter the new value and hit ENTER to validate the new value. You can also manually move the high resolution image by 1 or 5 pixels either way using the -, - -, + and + + buttons.\nAs soon as the scaling factor, xoffset and yoffset values differ from the values calculated by the automatic mode, the overlay mode in the table of list of files will display Manual.\nProfiler tool Turn on the profiler tool to get a live profile plot of the vertical and horizontal high resolution and low resolution profiles around the cursor position. This will help overlaying the two images.\nTransparency Using the transparency feature allows to see \u0026ldquo;through\u0026rdquo; the high resolution image, the low resolution to help the overlay.\nOnce you are satisfied with the overlay of the \u0026ldquo;working\u0026rdquo; images, click the Manually overlay all images in order to apply that settings to all the images. Once all the images have been overlaid, the export overlaid images button becomes available.  Export the final images Click the Export overlaid images button to export the overlaid images. Each TIFF image created will have a few of new metadata infos:\n scaling factor xoffset yoffset  "
},
{
	"uri": "/tutorial/notebooks/panoramic_stitching/",
	"title": "Panoramic Stitching",
	"tags": [],
	"description": "",
	"content": " Notebook name: panoramic_stitching.ipynb\nDescription The main goal of this notebook is to stitch a set of images as shown here.\nThis notebook takes a set of folders as input, such as the one created by the group_images_by_cycle_for_panoramic_stitching. You need to manually stitch the images of one of those folders and then the notebook will apply the same settings to all the other folders by matching motor_position/pixel_offset.\nBy default this notebook is defined to look for the 2 motor parameters called MotLiftTable.RBV and MotLongAxis.RBV. (contact Jean Bilheux to customize the notebook to other motor names).\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Folders to Process Using the folder selector tool, select all the folders you want to work on. Each folder must contain the TIFF images of a single panoramic stitching (all the images of that folder will be stitched together).\nNeed help using the File Selector?\n Interface Presentation How Does it Work ? Ths UI has been designed to help you stitch all the images of the first, by default, folder selected. Once this is done, you will click the Automatic stitch all other folders using those parameters button to stitch all the other folders/images. Then you can export the panoramic images created as TIFF.\nStep by Step Step 1 - stitch one group of images (any of them will work) The top left corner image, first image/file from the list, is fixed. This is the reason why selecting the first raw in the table will display a blue border around the image.\nAny other row selected will display a red border around the image selected. You have three options to move those images.\n using the mouse using manual offset button to jump by 1 or 5 pixels at a time entering offset values directly in the table  Using the Mouse\nTo activate the mouse mode, click the From -\u0026gt; To pointer switch at the top of the UI. This will brings a couple of target labels FROM and TO within the panoramic view. Simply move the FROM target within the image selected region, inside the red box, to a feature you recognized in the previous image stitched. Move the TO target to that same feature and then click Move image of active ro FROM -\u0026gt; TO to reposition that image.\nthe Move image of active row FROM -\u0026gt;TO button will be enabled only when the FROM target is within the image selected (surrounded by a red border).\n The UI provides an horizontal and vertical profiler tool to help in the alignment of 2 images. Feel free to move around the horizontal and vertical profilers, resize them in length or width as illustrated here. The BLACK plot shows the profile from the reference image, the RED plot shows the profile of the working image.\n Using manual offset buttons\nUsing those buttons, you can move the working image by 1 or 5pixels at a time horizontally or vertically. The latest version of the notebook provides a remote control that will speed up the alignment process. You can easily jump to the previous or next image to work on, and you can bring all the alignment tools (FROM and TO cursors, horizontal and vertical profilers) into the current window view. This allows you to use full benefit of your monitor size by only working on the image view.  Using table\nYou can also directly entered the xoffset or yoffset of any image, except the first one, within the table. Double click the field you want to edit to change the x or y offset. A right click inside the table allows you to save, load or reset the content of the table  Step 2 - Repeat settings defined on all other folders Once you have completely aligned all first images of the current folders, you can repeat the settings on all the other folders by clicking the Automatically stitch all other folders using those offset parameters button. The program will calculate for each image the coefficient x and y offset versus motor position and then will apply that coefficient on the new images. This rule of 3 allows a perfect horizontal and vertical positions of the images. Once it\u0026rsquo;s done, simply browse through the folders to check the alignment of all the images.\nStep 3 - Create all panoramic images You need first to select the output location where the image will be created. A folder will be created based on the name of the input folders parent directory.\nThe final images are not created at this stage and only the position of each image is set. The final step, export will perform the stitching using the algorithm you will select.\nStep4 - Export all panoramic images Click the bottom right button to export all the panoramic images.\nA progress bar at the bottom will show you that the notebook is calculating the result of using various stitching algorithms on the current working set of images. Once it\u0026rsquo;s done, a dialog box will display those images side by side to allow you to pick the best one for your data set.\nFeel free to zoom/pan within any of the images to compare the results\nThe 3 algorithms available for now are:\n use minimum counts use maximum counts use mean counts  Use minimum counts will take the pixel of lower intensity in the overlap region\nUse maximum counts will take the pixel of higher intensity\nUse mean counts will take the average of the two pixels\nOnce you click OK, you will need to select where your want to create the output folder. The name of the folder that the program is going to create will be based on the input folder name and the name of the algorithm selected.\nFor example:\n top parent folder: raw_normalized_sorted_by_cycle algorithm selected: minimum counts output folder will be raw_normalized_sorted_by_cycle_panoramic_minimum_counts  "
},
{
	"uri": "/tutorial/notebooks/panoramic_stitching_for_tof/",
	"title": "Panoramic Stitching for TOF",
	"tags": [],
	"description": "",
	"content": " Notebook name: panoramic_stitching_for_tof.ipynb\nDescription This notebook stitches images acquired in TOF mode.\nThe notebook takes a set of folders as input. Each folder corresponds to a different coverage of the sample and contains all the TOF images acquired using the MCP detector. You will need to manually position either the integrated signal over all the TOF, or the best contrast image (calculated using the Dual energy algorithm described in the notebook dual energy). Then the program will stitch every single tof image using those same parameters. At the end you will have a folder of the stitch images with as many images as any of the input folder.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Folders to Process Using the folder selector tool, select all the folders you want to work on. Each folder must contain the TIFF images of a single panoramic stitching (all the images of that folder will be stitched together).\nNeed help using the File Selector?\n How Does it Work ? This UI has been designed to automatically stitch all the images of the various TOF/lambda after manually stitch the integrated or best contrast images.\nStep by Step Tutorial Step 1 - Select with which image you want to work The first tab Calculate best contrast images allows you to determine the images with the best contrast. 2 options are offered:\n Integrated image Best contrast image  The Integrated images are for each folder selected the sum of all the images. The best contrast image uses the algorithm defined in the dual energy notebook). Feel free to play with the binning size to improve the contrast. Once you are happy with the image mode you selected, just move on to the next tab Coarse alignment.\nStep 2 - Coarse Alignment Because the images produced in TOF mode do not have the position of the motor as metadata, it\u0026rsquo;s up to you to roughly determine their position using the table. Just select all the images, and only one time, and position them relative to each other. Once you are happy with your selection, click the Validate Coarse Alignment button to record those positions. You can now move on to the next and final step.\nStep 3 - Fine Alignment The top left corner image, first image/file from the list, is fixed. This is the reason why selecting the first raw in the table will display a blue border around the image.\nAny other row selected will display a red border around the image selected. You have three options to move those images.\n using the mouse using manual offset button to jump by 1 or 5 pixels at a time entering offset values directly in the table  Using the Mouse\nTo activate the mouse mode, click the From -\u0026gt; To pointer switch at the top of the UI. This will brings a couple of target labels FROM and TO within the panoramic view. Simply move the FROM target within the image selected region, inside the red box, to a feature you recognized in the previous image stitched. Move the TO target to that same feature and then click Move image of active ro FROM -\u0026gt; TO to reposition that image.\nthe Move image of active row FROM -\u0026gt;TO button will be enabled only when the FROM target is within the image selected (surrounded by a red border).\n The UI provides an horizontal and vertical profiler tool to help in the alignment of 2 images. Feel free to move around the horizontal and vertical profilers, resize them in length or width as illustrated here. The BLACK plot shows the profile from the reference image, the RED plot shows the profile of the working image.\n Using manual offset buttons\nUsing those buttons, you can move the working image by 1 or 5pixels at a time horizontally or vertically. Using table\nYou can also directly entered the xoffset or yoffset of any image, except the first one, within the table. Double click the field you want to edit to change the x or y offset.\nExport panoramic images You can now repeat the alignment on all the TOF slices by clicking the Export Panoramic Images button. You will need to select the output folder where you want to create the final folder which will be named after the parent input folders name.\nFor the region of overlap between two images, the notebook simply takes the average of the two images as illustrated here.  "
},
{
	"uri": "/tutorial/notebooks/profile/",
	"title": "Profile",
	"tags": [],
	"description": "",
	"content": " Notebook name: profile.ipynb\nDescription We created this notebook to get very precise profile of samples. For example, if you want to select a profile of exactly the center of your cylindrical sample, then this notebook is for you.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Profile UI Presentation How Does it Work ? Tool to Help you Select the Profile(s) The guide (red box surrounding the profile) is only there to help you define and move your profile with precision. Once the profile has been defined, disable the guide to lock the position of the profile.\nProfiles Plots The profile plots of the current image selected are displayed at the bottom of the interface.\nAll Profiles / All Images By going to the tab All Profiles / All Images, you can display on the same plot the profiles you select with the images you select.\nExport Profiles After clicking the Export Profiles\u0026hellip; button, and selecting an output folder, each profile will produce an ascii file. The top of this ascii file contains some metadata such as size of profile, list of input file name\u0026hellip;. Then the profile for each file will be saved into a comma separated table where each column is a file.\n"
},
{
	"uri": "/tutorial/notebooks/radial_profile/",
	"title": "Radial Profile",
	"tags": [],
	"description": "",
	"content": " Notebook name: radial_profile.ipynb\nDescription This notebook allows you to display and export the radial profile of a set of images. Radial profile means that, after defining the center of your profile region, the closest pixel to the center will produces the first data point. Then the next ones will produces the second data point (average counts over the set of each pixels).\nConfusing!\nWell the following drawings should help you understand how that works.\nFull circle  Step1: User defined the center of the profile (Red pixel in this example) Step2: User defined the sector to use (in this case, we used the entire sector 0 -\u0026gt; 360degrees) Program then calculate the position of each pixel relative to the new center defined Program order the pixels by their distance relative to the center. All the pixels at the same distance from the center will have their counts averaged. Profile of Counts vs pixel index position is then calculated.   Sector  Step1: User defined the center of the profile (Red pixel in this example) Step2: User defined the sector to use Program keeps only the pixel that are within the sector defined Program then calculate the position of each pixel relative to the new center defined Program order the pixels by their distance relative to the center. All the pixels at the same distance from the center will have their counts averaged. Profile of Counts vs pixel index position is then calculated.   Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Profile UI Presentation After running the lauch User Interface cell, the following GUI pops up.\nSelection of Sector Center Using the mouse, click the vertical and then horizontal lines on the image window to define the center of the sector.\nSelection of Sector Range Grid Settings It\u0026rsquo;s possible to change the settings of the grid (usefull when color of image and grid are too close).\nMaximum Radius By default, the entire range of pixels from the center to the side of the image is used. But it\u0026rsquo;s possible to narrow down that range to a given number of pixels using that tool. Turn on the Max radius option. Play with the slider to set the size of the pixel range.\nCalculate Radial Profiles Jump to the Profile tab and click the Calculate Profiles to calculate the radial profile of each image loaded. All those profiles will be displayed in the same plot below.\nExport Profiles Once the calculation of all profiles has been performed, the Export Profiles button becomes available. Click the Export Profiles \u0026hellip; and select where you want to create the ascii files.\nFile Name Convention The ASCII files creates will have the names bases such as\n\u0026lt;name_of_image\u0026gt;_profile_c_x\u0026lt;x_center\u0026gt;_y\u0026lt;y_center\u0026gt;angle\u0026lt;from_angle_in_deg\u0026gt;to\u0026lt;to_angle_in_deg\u0026gt;.txt\nwhere:\n name_of_image: is the name of the source image without the extension (20170811_Nautical_compass_0030_356_250_1875) x_center: the x axis position of the center (1024.0) y_center: the y axis position of the center (1024.0) from_angle_in_deg: starting sector angle in degrees (24.0) to_angle_in_deg: ending sector angle in degrees (137.0)  giving a name of\n20170811_Nautical_compass_0030_356_250_1875_profile_c_x1024.0_y1024.0_angle_24.0_to_137.0.txt\nFile Format Each ASCII file produced start with the following metadata\n# source image: /Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19621-CLOCK/CT/20170811_Nautical_compass_0030_356_250_1875.tiff # center [x0, y0]: [1024.0,1024.0] # angular range from 24.0degrees to 137.0degrees #pixel_from_center, Average_counts  "
},
{
	"uri": "/tutorial/notebooks/registration/",
	"title": "Registration",
	"tags": [],
	"description": "",
	"content": " Notebook name: registration.ipynb\nDescription This notebook will allow the registration (alignment) of a set of images using a reference image of your choice.\nHere are the steps (bold for user input/manipulation)\n Select the stack of images launch application Perform Auto alignment and/or Align images manually use profile to help in the alignment and sliders to check images overlap  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n Registration UI Registration Methods You will find 4 ways to register your data\n Automatic mode (let the program try to align your data for you) Manual mode (you have full control of how to move each of the image manually) Marker mode (define markers on the images and align them) Profile mode (use high contrast feature to align horizontally and vertically images)  \nAuto Registration Let the program perform auto-registration of all the images selected using the default first image as a reference by clicking Auto Registration\n\nManual Registration If you choose to manually align the images (except the reference image), click the Manual Registration button. Then move manually the images selected using the manual registration tool widgets.\n\nRegistration using Markers Click the Markers\u0026hellip; button to launch a new window.\nYou can define as manay markers as you want for each image. Then using Align images Using Markers button will align all the images according to the best overlap value of the markers.\nYou can copy/paste markers position using right click on the table.\n\nRegistration using Profiles Using a high contrast feature of the images (like a man made marker on the side of the sample), the program calculates the edge of this feature for all the images. This edge position (vertically and horizontally) is then used to register the images. If you are curious about the algorithm used to define the edge position, we are using the same algorithm as the water intake algorithm called sliding average.\n position the horizontal and vertical profiles on top of high contrast object change size (lenght and width) of profile regions if needed calculate edge (peak position) of marker in all images   select one of the bottom 3 options to export, save registered images.  Tools to Help You Grid You can add a grid on top of your images to help you in the manual alignment. Click the Grid \u0026gt; display at the top left corner of the UI. Then play with the slider to change the size of the grid.\nProfile You can display the profile of the image selected and of the reference image to help align the images.\nSimply move the edge of the profile lines. The profile of all the images selected (+ reference image) will be displayed.\nOpacity Slider The UI provides two types of opacity sliders.\n Selection vs Reference Image Images Selected  Selection vs Reference Image This slider will show up whenever at least one file, other than the reference image, is selected in the table (bottom of UI).\n When the cursor is at the top of the slider, the mean of all the images selected is displayed (100% of selection is displayed) When the cursor is at the bottom of the slider, only the reference image is displayed (0% of selection is displayed) All other position will display a x% of the selected images and then (1-x)% of the reference image.   Images Selected Whenever at least two images are selected (other than reference image), a checkbox labeled all and a slider will show up on the left of the UI.\nBy default all the images selected are display (mean of all images). But if you uncheck the all checkbox, then you can gradually display the imagess from the first one to the last one.\nThis slider will allow to go from the first image selected to the second by increasing the opacity of the first one, and decreasing the opacity of the second one. Once only the second image is display, keep moving the cursor will bring to display the third image and the second image will vanish.\nThe goal of this slider is to gradually display the images one by one.\nThe right slider to display current image vs reference image is always available.\n Export By clicking the Export \u0026hellip; button (bottom right) you will export the images registered into a folder you select.\nAdvanced users All the data registered can be access from the python notebook\n\u0026gt;\u0026gt;\u0026gt; data_registered = o_registration.data_dict \u0026gt;\u0026gt;\u0026gt; print(np.shape(data_registered['data'])) (8, 2048, 2048)  you can also reach the list of file names and their metadata\n\u0026gt;\u0026gt;\u0026gt; import pprint \u0026gt;\u0026gt;\u0026gt; pprint.pprint(data_registered['file_name']) ['/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0000.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0031.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0032.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0033.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0034.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0035.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0036.tif', '/Volumes/my_book_thunderbolt_duo/IPTS/IPTS-19921-Charles/02/im0037.tif'] \u0026gt;\u0026gt;\u0026gt; pprint.pprint(data_registered['metadata'][0]) {256: 2048, 257: 2048, 258: (16,), 259: 1, 262: 1, 270: 'slope = 2.13626E-05 \\roffset = 0.00000E+00\\r', 273: (8,), 277: 1, 278: 2048, 279: (8388608,), 282: 10.0, 283: 10.0, 296: 3, 320: (0,), 339: (1,)}  "
},
{
	"uri": "/tutorial/notebooks/rename_files/",
	"title": "Rename Files",
	"tags": [],
	"description": "",
	"content": " Notebook name: rename_files.ipynb\nDescription This notebook allows you to rename a set of files. You can define\n the prefix file name from scratch or used part of the old name the starting index the index number of digits  Main use of this notebook In this notebook, we will correctly format the file name index of the file selected. This allows the sorting of the file name to works all the time. For example, there are many cases where the images are saved using the following convention.\nWrong filename index\nimage_1.tif image_2.tif image_3.tif image_4.tif ... image_10.tif image_11.tif ... image_100.tif  Using this convention, any sorting algorithm will sort them as followed\nWrong sorting\nimage_1.tif image_10.tif image_100.tif ...  So this notebook will fix this issue by renaming the files\ncorrect filename index\nimage_001.tif image_002.tif image_003.tif image_004.tif ... image_010.tif image_011.tif ... image_100.tif  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nHow to Use It? Select your IPTS Check the full tutorial here\nSelect images to rename Using the file dialog tool, select the folder for which you want to renmame the files.\nOnly the most dominant file type (ex: tiff, fits) from the folder will be renamed\nDefine new naming schema Current schema name This is where you define the way the current file name is defined. You need to specify what string separates the first part of the file name with the index. If you decide to not fully rename the images, the string before this separator will be kept in the new file name.\nThe Random input dropdown list displays a random selection of the input files, to help you in defining the separator string. Play with it to make sure you correctly defined the current file name (what is prefix, what is a separator). Use the slider to the right of the file name prefix to define the prefix part of the name (as shown in the following animation).\nNew naming schema Here, you define if you want to keep the old prefix or not, the new prefix file name, index separator, number of digits and offset of this index.\nExample:\n old file name: experiment_0845454_10.tiff separator: _ new file name prefix: my_image number of digits: 4 offset: 15 new file name will be: my_image_0025.tiff  Result The bottom part of the cell will show the result of the naming on the first image selected.\nIf the new name shows an Error, checks your pre index separator.\nOutput folder You simply need to select where the new renamed file will be created. Then the program will copy the selected files and renamed them in the folder you selected.\nFeel free to check the dropdown list that shows the old name versus the new name of each file.\n"
},
{
	"uri": "/tutorial/notebooks/resonance_imaging_experiment_vs_theory/",
	"title": "Resonance Imaging Experiment vs Theory",
	"tags": [],
	"description": "",
	"content": "Notebook name: resonance_imaging_experiment_vs_theory.ipynb\n"
},
{
	"uri": "/tutorial/notebooks/rotate_and_crop_images/",
	"title": "Rotate and Crop Images",
	"tags": [],
	"description": "",
	"content": " Notebook name: rotate_and_crop_images.ipynb\nDescription You will use this notebook if you need to crop and/or rotate a set of images.\nThe application will ask you to select the images (FITS or TIFF) you want to modify. Then a User Interface (UI) will allow you to define the cropping region as well as the rotation angle to apply to the images. You will be able to browse through the images to check the result and then create the transformed images before exporting them to a new output folder as TIFF images.\nHow it Works Select your IPTS Need help using the IPTS selector?\n Select your Images Using the file selection tool, select the images you want to work with.\nOnce selected, your images will be automatically loaded.\nCrop and/or Rotate your Images This is where you will apply the correction to your images.\nHow to crop the images:  move the box around by clicking one of the edge and without releasing the mouse move the box to the new location resize the box by clicking the bottom right corner and dragging it to the new size.  How to rotate the images: Simply by entering the angle value in the text field. The angle is using the geometrical convention, with counter clock wise rotation direction.\nApply changes to all images: By clicking the apply on all images button, you will apply those correction to all images and quit this UI\nExport Images Using the folder selection tool, select where you want the output images to be created.\nThe program will automatically create a folder based on the rotation angle you defined\nFor example:\nA folder named rotated_0.5deg is created when the angle is 0.5 degrees.\n"
},
{
	"uri": "/tutorial/notebooks/select_ipts/",
	"title": "Select IPTS",
	"tags": [],
	"description": "",
	"content": " The select IPTS tool that you will find at the top of most of the notebooks allows you to quickly select your IPTS. This information will then be used by the program to quickly jump to that IPTS. Any file or folder selection will starts from this IPTS project, this way you won\u0026rsquo;t have to look around to find your data.\nSelect your Instrument Due to the success of the imaging technique ( :-) ), we are not limited to HFIR anymore. That means you will need to select your instrument to allow to list the IPTS of this particular beam line.\nEnter IPTS Use the top text box to specify your IPTS number. As you enter the number, the program check if the IPTS exists or not. A message will be displayed on the right side informing you if the file exist or not.\nIf the IPTS can be located, the second widget (list of IPTS) will automatically jump to that folder.\nSelect IPTS The second widget list all the IPTS found for your instrument (Imaging by default). Just select your IPTS.\nHELP Button Brings a new window in your browser with this help page.\nLive Demo "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tutorial/notebooks/template_ui/",
	"title": "Template UI Builder",
	"tags": [],
	"description": "",
	"content": " Notebook name: template_ui.ipynb\nDescription This notebook was implemented for the most aventurous python developers. This notebook offers the minimum required to start the development of a more complex user interface (UI).\nThe notebook is limited to the following features\n select your instrument/IPTS select list of images UI comes to life and there you can\n slide through the images to display them display name of image selected   Description of the notebook Select your IPTS Need help using the IPTS selector?\n Select your images Using the files selection tool, select the images you want to fix.\nDisplay images This is where the UI will comes to life. In order to improve or modify this ui, you will need to edit the file __code/template_ui.py\nfrom IPython.core.display import HTML from IPython.display import display import pyqtgraph as pg try: from PyQt4.QtGui import QFileDialog from PyQt4 import QtCore, QtGui from PyQt4.QtGui import QMainWindow except ImportError: from PyQt5.QtWidgets import QFileDialog from PyQt5 import QtCore, QtGui from PyQt5.QtWidgets import QApplication, QMainWindow from NeuNorm.normalization import Normalization from __code.ui_template import Ui_MainWindow as UiMainWindow from __code.file_folder_browser import FileFolderBrowser class InterfaceHandler(FileFolderBrowser): def __init__(self, working_dir=''): super(InterfaceHandler, self).__init__(working_dir=working_dir) def load(self): list_images = self.list_images_ui.selected o_norm = Normalization() o_norm.load(file=list_images, notebook=True) self.o_norm = o_norm class Interface(QMainWindow): live_data = [] def __init__(self, parent=None, o_norm=None): display(HTML('\u0026lt;span style=\u0026quot;font-size: 20px; color:blue\u0026quot;\u0026gt;Check UI that poped up \\ (maybe hidden behind this browser!)\u0026lt;/span\u0026gt;')) self.o_norm = o_norm self.list_files = self.o_norm.data['sample']['file_name'] self.list_data = self.o_norm.data['sample']['data'] QMainWindow.__init__(self, parent=parent) self.ui = UiMainWindow() self.ui.setupUi(self) self.init_statusbar() self.setWindowTitle(\u0026quot;Template UI\u0026quot;) self.ui.image_view = pg.ImageView() self.ui.image_view.ui.roiBtn.hide() self.ui.image_view.ui.menuBtn.hide() bottom_layout = QtGui.QHBoxLayout() # file index slider label_1 = QtGui.QLabel(\u0026quot;File Index\u0026quot;) self.ui.slider = QtGui.QSlider(QtCore.Qt.Horizontal) self.ui.slider.setMaximum(len(self.list_files) - 1) self.ui.slider.setMinimum(0) self.ui.slider.valueChanged.connect(self.file_index_changed) # spacer spacer = QtGui.QSpacerItem(40, 20, QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Minimum) bottom_layout.addWidget(label_1) bottom_layout.addWidget(self.ui.slider) bottom_layout.addItem(spacer) bottom_widget = QtGui.QWidget() bottom_widget.setLayout(bottom_layout) vertical_layout = QtGui.QVBoxLayout() vertical_layout.addWidget(self.ui.image_view) vertical_layout.addWidget(bottom_widget) self.ui.widget.setLayout(vertical_layout) self.init_widgets() self.file_index_changed() def init_widgets(self): pass def init_statusbar(self): self.eventProgress = QtGui.QProgressBar(self.ui.statusbar) self.eventProgress.setMinimumSize(20, 14) self.eventProgress.setMaximumSize(540, 100) self.eventProgress.setVisible(False) self.ui.statusbar.addPermanentWidget(self.eventProgress) def apply_clicked(self): # do stuff self.close() def cancel_clicked(self): self.close() def file_index_changed(self): file_index = self.ui.slider.value() new_live_image = self.list_data[file_index] self.ui.image_view.setImage(new_live_image) self.ui.file_name.setText(self.list_files[file_index]) def display_image(self, image): self.ui.image_view.setImage(image) def closeEvent(self, eventhere=None): print(\u0026quot;Leaving Parameters Selection UI\u0026quot;)  "
},
{
	"uri": "/tutorial/notebooks/topaz_config_generator/",
	"title": "TOPAZ config file generator",
	"tags": [],
	"description": "",
	"content": " Notebook name: TOPAZ_config_generator.ipynb\nStart the Notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nFirst Time Look If you are using the notebook for the first time, it should look like this\nDefine IPTS Starting from the top SHIFT + ENTER the cells in order to run them. The 4th cell will ask you to select the IPTS of your experiment.\nInitialize Parameters Using Config File (Optional) In case you want to initialize the content of all the widgets by a config file you created in the past, you can simply select that config file.\nRun All Cells at Once Select the next cell and click Cell \u0026gt; Run All Below.\nFile or Folder Selection Tool In order to select a file or a folder you need to know the following:\n one dot (.) means current folder 2 dots (..) means above folder click select to validate your file or folder selection selection made will be display above the selection tool   Widget Interaction You will find that some of the widgets display depends on your input in other widgets. This has been implemented to help you in your choice of parameters.\nAdvanced Options Instrument scientists and super users can have access to advanced options by entering a pasword in the Advanced Options cell.\nCreate Config File And finally, re-run the last cell Export the Config File in order to produce the config file. If any information is missing, a text will show you what is missing. Just click on this link to quickly jump to the widgets in the notebook.\nIf nothing is missing, the full path to the config file created will be displayed!\nFor advanced users who entered the instrument password, they will have a preview of the config file when creating the configuration file.  Run Reduction The next cell will build up the command line you will need to copy/paste into a terminal. To do so\n Copy the command line green text using Right click + Copy \u0026hellip; click the terminal icon at the top of the desktop Paste the text hit ENTER  "
},
{
	"uri": "/tutorial/notebooks/water_intake_profile_calculator/",
	"title": "Water Intake Profile Calculator",
	"tags": [],
	"description": "",
	"content": " Notebook name: water_intake_profile_calculator.ipynb\nDescription This notebook will calculate the water intake profile vs time of a sample.\nThis application is still under heavy development. The look of the UI will differ from the screenshot you can see in this tutorial and features are added on a regular basis. The tutorial will be fully rewrite once the development is done.  Here are the steps (bold for user input/manipulation)\n select the normalized images images sorted by time (by default) User Interface pops up! region of interest selected (optional) change the sorting algorithm  by name by date  (optional) select a folder containing the original .dsc files (which contain the right time stamp) profile of counts vs vertical-pixel calculated (select integrated algorithm: mean/median/sum) water intake profile vs file index or vs time export profiles  Start the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Images to Process Select the images you want to process using the File Selector. Once you click the Select button, the time stamp and the images will be automatically loaded. Wait for the progress bar to be done.\nNeed help using the File Selector?\n \nWater Intake Calculator UI Resizing widgets It\u0026rsquo;s possible to resize or move any of the plots.\nSorting Algorithm By default, all the images are sorted using their time stamps. But in some cases (old IPTS), the time stamp may be wrong. So It\u0026rsquo;s possible to:\n either sort them using their name and let you define the time interval between the runs define a folder that contains the .dsc files created by the MCP. Those files contain in all cases, the correct time stamp.   Profile Algorithm You can select the profile algorithm to use (to integrate over the x-axis of the region selected) using the profile algorithms available\n add mean median  The profile is calculated using the following method:\n retrieve the region you defined in the top left image using the profile algorithm you selected, will integrate over the x-axis of the ROI display the profile vs the y-pixels.  Using Pixel or Size Reference By default the water intake profile display the position of the \u0026ldquo;wave\u0026rdquo; as a pixel number vs the time. But it\u0026rsquo;s also possible to display this one using a real dimension (mm). To do so, just click the water intake y_axis -\u0026gt; distance check box and define the dimension of the pixel.\nIntegration Direction In the new version of the application, it is now possible to specify the direction of integration of the profiles. Select either y_axis or x_axis to change this direction.\nWater Intake Algorithms It\u0026rsquo;s possible to chose between 2 different algorithms to calculate the \u0026ldquo;wave\u0026rdquo; front position.\nSliding Average This method is fully demonstrated in this PDF document\nError Function Fitting The signal is fitted using a modified version of the error function as shown here\nChange Point You can now select a 3rd algorithm based on the following python library (changepy)\nRebin For very poor statistics data, you can rebin the data by 2, 3 or more pixels. This will decrease the resolution of the water intake peak position, but will improve its calculation by the various algorithms (sliding average, error function, \u0026hellip;)\nLive Demo Export Results You can export the following data\n profile (Export \u0026gt; Profiles \u0026hellip;) water intake (Export \u0026gt; Water Intake \u0026hellip;) Table (Export Table \u0026hellip;, on the right of the table)  For Advanced Users. keep reading!\n Want to Work on the Data in the Notebook? If you want to play yourself with the data loaded, you can easily access all the data and metadata loaded\nlist_of_data = o_gui.dict_data['list_data']  list_of_files = o_gui.dict_data['list_images']  list_of_time_stamp = o_gui.dict_data['list_time_stamp'] list_of_time_stamp_user_format = o_gui.dict_data['list_time_stamp_user_format']  "
},
{
	"uri": "/tutorial/notebooks/wave_front_dynamics/",
	"title": "Wave Front Dynamics",
	"tags": [],
	"description": "",
	"content": " Notebook name: wave_front_dynamics.ipynb\nDescription The main goal of this notebook is to follow the evolution of a wave front over time.\nThe ASCII input data files are produced by other notebooks such as the Radial Profile notebook.\nThis notebook will produce an ASCII file of the edge position according to the selected algorithms.\nStart the notebook If you need help accessing this notebook, check the How To \u0026gt; Start the python notebooks tutorial.\nSelect your IPTS Need help using the IPTS selector?\n Select Profiles Files to Process Select the profiles files you created (using Radial Profile) using the File Selector.\nNeed help using the File Selector?\n UI Presentation Running the next cell will bring the user interface (UI) to life.\nPrepare Data Tab Step 1 Make sure you want to perform the calculation on all the files loaded. If you want to exclude any of the files, select the file using the file index slider and turn off the Use this file checkbox.\nStep 2 To help the algorithm, select the range of data to use to detect the edge and try to exclude any signal you don\u0026rsquo;t care.\nStep 3 To improve statistics and speed, play with the rebin parameters (size and type). We noticed that in nearly all cases, binning will speed up the algorithms and will help finding the right edge.\nEdge Calculation Tab Once you are done preparing the data, it\u0026rsquo;s time to detect the edge position. 3 algorithms are available and can be used at the same time to compare the results. Depending on the signal, such or such algorithm may work better than another one.\nList of algorithms available Sliding Average Check the following document to learn about the algorithm behind it PDF document\nError function The signal is fitted using a modified version of the error function as shown here Change point This algorithm uses the following python library (changepy)\nRun algorithms Select the algorithms you want to use, or click *ALL to use all of them, then click Run Algorithm Selected\nExport Data Click the Export \u0026hellip; button to create the final ascii file. Select the output folder and click OK.\n"
}]